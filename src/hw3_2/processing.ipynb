{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>sldatime</th>\n",
       "      <th>pno</th>\n",
       "      <th>cno</th>\n",
       "      <th>cmrid</th>\n",
       "      <th>vipno</th>\n",
       "      <th>id</th>\n",
       "      <th>pluno</th>\n",
       "      <th>bcd</th>\n",
       "      <th>...</th>\n",
       "      <th>bndno</th>\n",
       "      <th>bndname</th>\n",
       "      <th>qty</th>\n",
       "      <th>amt</th>\n",
       "      <th>disamt</th>\n",
       "      <th>ismmx</th>\n",
       "      <th>mtype</th>\n",
       "      <th>mdocno</th>\n",
       "      <th>isdel</th>\n",
       "      <th>just_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19869</th>\n",
       "      <td>1322202</td>\n",
       "      <td>16040109531802715</td>\n",
       "      <td>2016-04-01 09:53:45</td>\n",
       "      <td>18</td>\n",
       "      <td>8307</td>\n",
       "      <td>女[26 - 30]</td>\n",
       "      <td>2900000863286</td>\n",
       "      <td>3</td>\n",
       "      <td>24011108</td>\n",
       "      <td>215087708729025980</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.598000</td>\n",
       "      <td>87.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>476579</td>\n",
       "      <td>16040109531802715</td>\n",
       "      <td>2016-04-01 09:53:45</td>\n",
       "      <td>18</td>\n",
       "      <td>8307</td>\n",
       "      <td>女[26 - 30]</td>\n",
       "      <td>2900000863286</td>\n",
       "      <td>2</td>\n",
       "      <td>14845009</td>\n",
       "      <td>6936749501109</td>\n",
       "      <td>...</td>\n",
       "      <td>14104.000000</td>\n",
       "      <td>好侍</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>476578</td>\n",
       "      <td>16040109531802715</td>\n",
       "      <td>2016-04-01 09:53:45</td>\n",
       "      <td>18</td>\n",
       "      <td>8307</td>\n",
       "      <td>女[26 - 30]</td>\n",
       "      <td>2900000863286</td>\n",
       "      <td>1</td>\n",
       "      <td>14845009</td>\n",
       "      <td>6936749501109</td>\n",
       "      <td>...</td>\n",
       "      <td>14104.000000</td>\n",
       "      <td>好侍</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555</th>\n",
       "      <td>1365213</td>\n",
       "      <td>16040110071802720</td>\n",
       "      <td>2016-04-01 10:07:00</td>\n",
       "      <td>18</td>\n",
       "      <td>8307</td>\n",
       "      <td>女[26 - 30]</td>\n",
       "      <td>2900001437424</td>\n",
       "      <td>1</td>\n",
       "      <td>14525018</td>\n",
       "      <td>6901447007406</td>\n",
       "      <td>...</td>\n",
       "      <td>14650.000000</td>\n",
       "      <td>蓝岸</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>快讯促销</td>\n",
       "      <td>521866151357516.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>711991</td>\n",
       "      <td>16040110071802720</td>\n",
       "      <td>2016-04-01 10:07:00</td>\n",
       "      <td>18</td>\n",
       "      <td>8307</td>\n",
       "      <td>女[26 - 30]</td>\n",
       "      <td>2900001437424</td>\n",
       "      <td>2</td>\n",
       "      <td>15605013</td>\n",
       "      <td>6923644267070</td>\n",
       "      <td>...</td>\n",
       "      <td>15052.000000</td>\n",
       "      <td>蒙牛</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                uid            sldatime  pno   cno  \\\n",
       "19869     1322202  16040109531802715 2016-04-01 09:53:45   18  8307   \n",
       "6322       476579  16040109531802715 2016-04-01 09:53:45   18  8307   \n",
       "6321       476578  16040109531802715 2016-04-01 09:53:45   18  8307   \n",
       "20555     1365213  16040110071802720 2016-04-01 10:07:00   18  8307   \n",
       "10456      711991  16040110071802720 2016-04-01 10:07:00   18  8307   \n",
       "\n",
       "            cmrid          vipno  id     pluno                 bcd  \\\n",
       "19869  女[26 - 30]  2900000863286   3  24011108  215087708729025980   \n",
       "6322   女[26 - 30]  2900000863286   2  14845009       6936749501109   \n",
       "6321   女[26 - 30]  2900000863286   1  14845009       6936749501109   \n",
       "20555  女[26 - 30]  2900001437424   1  14525018       6901447007406   \n",
       "10456  女[26 - 30]  2900001437424   2  15605013       6923644267070   \n",
       "\n",
       "          ...            bndno bndname      qty       amt   disamt  ismmx  \\\n",
       "19869     ...        -1.000000      -1 2.598000 87.290000 0.000000      0   \n",
       "6322      ...     14104.000000      好侍 1.000000 10.600000 0.000000      0   \n",
       "6321      ...     14104.000000      好侍 1.000000 10.600000 0.000000      0   \n",
       "20555     ...     14650.000000      蓝岸 1.000000 16.990000 0.000000      1   \n",
       "10456     ...     15052.000000      蒙牛 1.000000  4.900000 0.000000      0   \n",
       "\n",
       "      mtype                 mdocno  isdel   just_date  \n",
       "19869    -1              -1.000000      0  2016-04-01  \n",
       "6322     -1              -1.000000      0  2016-04-01  \n",
       "6321     -1              -1.000000      0  2016-04-01  \n",
       "20555  快讯促销 521866151357516.000000      0  2016-04-01  \n",
       "10456    -1              -1.000000      0  2016-04-01  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "df = pd.read_csv(\"trade_new.csv\", delimiter=',', parse_dates=['sldatime'], date_parser=dateparse).fillna(-1)\n",
    "df = df.sort_values('sldatime')\n",
    "# train\n",
    "# directory = \"train\"\n",
    "# feature_extract_df = df.copy().query('20160201 <= sldatime < 20160601')\n",
    "# last_week_df = df.copy().query('20160525 <= sldatime < 20160601')\n",
    "# last_month_df = df.copy().query('20160501 <= sldatime < 20160601')\n",
    "# label_df = df.copy().query('20160601 <= sldatime < 20160701')\n",
    "# feature_extract_df[\"just_date\"] = feature_extract_df['sldatime'].dt.date\n",
    "# last_week_df[\"just_date\"] = last_week_df['sldatime'].dt.date\n",
    "# last_month_df[\"just_date\"] = last_month_df['sldatime'].dt.date\n",
    "# global_x_axis = [1.0, 2.0, 3.0, 4.0]\n",
    "# global_month_names = [\"first\", \"second\", \"fourth\", \"fifth\"]\n",
    "\n",
    "# test\n",
    "# directory = \"test\"\n",
    "# feature_extract_df = df.copy().query('20160301 <= sldatime < 20160701')\n",
    "# last_week_df = df.copy().query('20160624 <= sldatime < 20160701')\n",
    "# last_month_df = df.copy().query('20160601 <= sldatime < 20160701')\n",
    "# label_df = df.copy().query('20160701 <= sldatime < 20160801')\n",
    "# feature_extract_df[\"just_date\"] = feature_extract_df['sldatime'].dt.date\n",
    "# last_week_df[\"just_date\"] = last_week_df['sldatime'].dt.date\n",
    "# last_month_df[\"just_date\"] = last_month_df['sldatime'].dt.date\n",
    "# global_x_axis = [1.0, 2.0, 3.0, 4.0]\n",
    "# global_month_names = [\"first\", \"second\", \"fourth\", \"fifth\"]\n",
    "\n",
    "# predict\n",
    "directory = \"predict\"\n",
    "feature_extract_df = df.copy().query('20160401 <= sldatime < 20160801')\n",
    "last_week_df = df.copy().query('20160725 <= sldatime < 20160801')\n",
    "last_month_df = df.copy().query('20160701 <= sldatime < 20160801')\n",
    "# label_df = df.copy().query('20160801 <= sldatime < 20160901')\n",
    "feature_extract_df[\"just_date\"] = feature_extract_df['sldatime'].dt.date\n",
    "last_week_df[\"just_date\"] = last_week_df['sldatime'].dt.date\n",
    "last_month_df[\"just_date\"] = last_month_df['sldatime'].dt.date\n",
    "global_x_axis = [1.0, 2.0, 3.0, 4.0]\n",
    "global_month_names = [\"first\", \"second\", \"fourth\", \"fifth\"]\n",
    "\n",
    "feature_extract_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMonthlyNames(prefix, suffix):\n",
    "    global global_month_names\n",
    "    month_names = global_month_names\n",
    "    res_list = []\n",
    "    for n in month_names:\n",
    "        res_list.append(prefix + \"_\" + n + \"_\" + suffix)\n",
    "    return res_list\n",
    "def getTotalCounts(i_df, group_by, use_col, new_col_name, isUnique):\n",
    "    input_df = i_df.copy()\n",
    "    res_df = None\n",
    "    if isUnique:\n",
    "        res_df = input_df.groupby(group_by)[use_col].nunique().reset_index().fillna(0)\n",
    "    else:\n",
    "        res_df = input_df.groupby(group_by)[use_col].count().reset_index().fillna(0)\n",
    "    res_df.columns = group_by + [new_col_name]\n",
    "    return res_df\n",
    "\n",
    "def getMonthlyCounts(i_df, group_by, use_col, new_cols_name, isUnique):\n",
    "    input_df = i_df.copy()\n",
    "    input_df.index = input_df[\"sldatime\"]\n",
    "    res_df = None\n",
    "    if isUnique:\n",
    "        res_df = input_df.groupby(group_by + [input_df.index.month])[use_col].nunique().unstack().reset_index().fillna(0)\n",
    "    else:\n",
    "        res_df = input_df.groupby(group_by + [input_df.index.month])[use_col].count().unstack().reset_index().fillna(0)\n",
    "    res_df = res_df.rename_axis(None, axis=1)\n",
    "    res_df.columns = group_by + new_cols_name\n",
    "#     print(group_by + new_cols_name)\n",
    "    return res_df\n",
    "\n",
    "def getTotalSum(i_df, group_by, use_col, new_col_name):\n",
    "    input_df = i_df.copy()\n",
    "    res_df = None\n",
    "    res_df = input_df.groupby(group_by)[use_col].sum().reset_index().fillna(0)\n",
    "    res_df.columns = group_by + [new_col_name]\n",
    "    return res_df\n",
    "\n",
    "def getMonthlySum(i_df, group_by, use_col, new_cols_name):\n",
    "    input_df = i_df.copy()\n",
    "    input_df.index = input_df[\"sldatime\"]\n",
    "    res_df = None\n",
    "    res_df = input_df.groupby(group_by + [input_df.index.month])[use_col].sum().unstack().reset_index().fillna(0)\n",
    "    res_df = res_df.rename_axis(None, axis=1)\n",
    "    res_df.columns = group_by + new_cols_name\n",
    "    return res_df\n",
    "\n",
    "def getMonthAgg(monthly_df, index_cols, start, basic_name):\n",
    "    input_df = monthly_df.copy()\n",
    "    res_df = monthly_df.copy()\n",
    "    mean_name = basic_name + \"_mean\"\n",
    "    std_name = basic_name + \"_std\"\n",
    "    max_name = basic_name + \"_max\"\n",
    "    median_name = basic_name + \"_median\"\n",
    "    res_df[mean_name] = input_df.iloc[:,start:].mean(axis=1)\n",
    "    res_df[std_name] = input_df.iloc[:,start:].std(axis=1)\n",
    "    res_df[max_name] = input_df.iloc[:,start:].max(axis=1)\n",
    "    res_df[median_name] = input_df.iloc[:,start:].median(axis=1)\n",
    "    res_df = res_df[index_cols + [mean_name, std_name, max_name, median_name]]\n",
    "    return res_df\n",
    "\n",
    "def getUIBCAgg(input_df, group_by, save_col, use_col, start, basic_name, agg_type):\n",
    "    res_df = None\n",
    "    if agg_type == 0:\n",
    "        input_df = input_df.copy().groupby(group_by)[use_col].count().unstack().reset_index().rename_axis(None, axis=1)\n",
    "    elif agg_type == 1:\n",
    "        input_df = input_df.copy().groupby(group_by)[use_col].nunique().unstack().reset_index().rename_axis(None, axis=1)\n",
    "    elif agg_type == 2:\n",
    "        input_df = input_df.copy().groupby(group_by)[use_col].sum().unstack().reset_index().rename_axis(None, axis=1)\n",
    "    res_df = input_df.copy()\n",
    "    mean_name = basic_name + \"_mean\"\n",
    "    std_name = basic_name + \"_std\"\n",
    "    max_name = basic_name + \"_max\"\n",
    "    median_name = basic_name + \"_median\"\n",
    "    res_df[mean_name] = input_df.iloc[:,start:].mean(axis=1).fillna(0)\n",
    "    res_df[std_name] = input_df.iloc[:,start:].std(axis=1).fillna(0)\n",
    "    res_df[max_name] = input_df.iloc[:,start:].max(axis=1).fillna(0)\n",
    "    res_df[median_name] = input_df.iloc[:,start:].median(axis=1).fillna(0)\n",
    "    res_df = res_df[[save_col, mean_name, std_name, max_name, median_name]]\n",
    "    return res_df\n",
    "\n",
    "def getRepeatFeature(input_df, group_by, basic_name):\n",
    "    res_df = None\n",
    "    i_df = input_df.copy()\n",
    "    temp = getTotalCounts(i_df, group_by, \"just_date\", \"temp_counts\", True)\n",
    "    temp2 = getTotalCounts(feature_extract_df, [group_by[0]], group_by[1], \"temp2_total_buyer_counts\", True)\n",
    "    temp = temp.loc[temp[\"temp_counts\"] > 1]\n",
    "    temp = getTotalCounts(temp, [group_by[0]], group_by[1], basic_name + \"_counts\", False)\n",
    "    res_df = temp2.merge(temp, how=\"left\").fillna(0)\n",
    "    res_df[basic_name+\"_ratio\"] = res_df[basic_name + \"_counts\"] / res_df[\"temp2_total_buyer_counts\"]\n",
    "    res_df = res_df[[group_by[0], basic_name+\"_counts\", basic_name+\"_ratio\"]]\n",
    "    return res_df\n",
    "\n",
    "def commonMergeDataFrame(input_dict, other_list = []):\n",
    "    res_df = None\n",
    "    for key, value in input_dict.items():\n",
    "        if res_df is None:\n",
    "            res_df = value\n",
    "            continue\n",
    "        if key not in other_list:\n",
    "            res_df = res_df.merge(value)\n",
    "        else:\n",
    "            res_df = res_df.merge(value, how=\"left\").fillna(0)\n",
    "    return res_df\n",
    "\n",
    "def getTrend(x):\n",
    "    global global_x_axis\n",
    "    a = global_x_axis\n",
    "    b = x[-len(global_x_axis):]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(a,b)\n",
    "    return slope\n",
    "                           \n",
    "def mergeProfileFrame(input_df_list):\n",
    "    res_df = None\n",
    "    for i in input_df_list:\n",
    "        if res_df is None:\n",
    "            res_df = i.copy()\n",
    "            continue\n",
    "        res_df = res_df.merge(i.copy())\n",
    "    return res_df\n",
    "def mergeFeatureWithLabel(feature_df, label_df, on_cols):\n",
    "    res_df = None\n",
    "    f_df = feature_df.copy()\n",
    "    l_df = label_df.copy()[on_cols]\n",
    "    l_df = l_df.drop_duplicates()\n",
    "    l_df[\"label\"] = \"1\"\n",
    "    res_df = f_df.merge(l_df, how=\"left\").fillna({\"label\": \"0\"})\n",
    "    res_df[[\"label\"]] = res_df[[\"label\"]].astype(int)\n",
    "    return res_df\n",
    "def isDifferent(raw_df, groupby, new_df):\n",
    "    s1 = raw_df[groupby].drop_duplicates().shape\n",
    "    s2 = new_df.shape\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    return s1[0] == s2[0]\n",
    "def getDeviation(raw_df, agg_df, index_cols, new_names, basic_name):\n",
    "    res_df = None\n",
    "    r_df = raw_df.copy()\n",
    "    a_df = agg_df.copy()\n",
    "    res_df = raw_df.merge(a_df)\n",
    "    res_df[\"few_months_ago_mean\"] = res_df.loc[:,new_names[0]:new_names[-2]].mean(axis=1)\n",
    "    res_df[\"few_months_ago_std\"] = res_df.loc[:,new_names[0]:new_names[-2]].std(axis=1)\n",
    "    res_df[basic_name+\"_bias\"] = res_df[new_names[-1]] - res_df[\"few_months_ago_mean\"]\n",
    "    res_df[basic_name+\"_bias_divide_mean\"] = res_df[basic_name+\"_bias\"] / res_df[\"few_months_ago_mean\"]\n",
    "    res_df[basic_name+\"_bias_divide_std\"] = res_df[basic_name+\"_bias\"] / res_df[\"few_months_ago_std\"]\n",
    "    res_df = res_df[index_cols+[basic_name+\"_bias\", basic_name+\"_bias_divide_std\", basic_name+\"_bias_divide_mean\"]]\n",
    "    where_are_nan = np.isnan(res_df)  \n",
    "    where_are_inf = np.isinf(res_df)  \n",
    "    res_df[where_are_nan] = 0  \n",
    "    res_df[where_are_inf] = 0 \n",
    "    return res_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(451, 1)\n",
      "(451, 133)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(451, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 463个用户\n",
    "user_profile_dict = {}\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. 用户购物总次数\n",
    "# 2. 用户购物花钱总金额\n",
    "# 3. Day Count - 用户购物总天数（频率）\n",
    "#\n",
    "user_profile_dict[\"up_plu_counts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\"], \"pluno\", \"up_plu_counts\", False)\n",
    "user_profile_dict[\"up_plu_sum_df\"] = getTotalSum(feature_extract_df, [\"vipno\"], \"amt\", \"up_plu_sum\")\n",
    "user_profile_dict[\"up_plu_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\"], \"just_date\", \"up_plu_day_ucounts\", True)\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. 用户购物月次数\n",
    "# 2. 用户购物花钱月金额\n",
    "# 3. 用户购物月天数（月频率）\n",
    "plu_monthly_counts_new_names = getMonthlyNames(\"up\", \"plu_counts\")\n",
    "user_profile_dict[\"up_monthly_plu_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\"], \"pluno\", plu_monthly_counts_new_names, False)\n",
    "plu_sum_new_names = getMonthlyNames(\"up\", \"plu_sum\")\n",
    "user_profile_dict[\"up_monthly_plu_sum_df\"] = getMonthlySum(feature_extract_df, [\"vipno\"], \"amt\", plu_sum_new_names)\n",
    "plu_day_ucounts_new_names = getMonthlyNames(\"up\", \"plu_day_ucounts\")\n",
    "user_profile_dict[\"up_monthly_plu_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\"], \"pluno\", plu_day_ucounts_new_names, False)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# whold period\n",
    "# 1. 购买的unique的I的总数量 -- (用户买过几种商品，去重)\n",
    "# 2. 购买的unique的B的总数量 -- (用户买过几种品牌，去重)\n",
    "# 3. 购买的unique的C的总数量 -- (用户买过几种类型，去重)\n",
    "user_profile_dict[\"up_plu_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\"], \"pluno\", \"up_plu_ucounts\", True)\n",
    "user_profile_dict[\"up_bnd_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\"], \"bndno\", \"up_bnd_ucounts\", True)\n",
    "user_profile_dict[\"up_dpt_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\"], \"dptno\", \"up_dpt_ucounts\", True)\n",
    "\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# monthly\n",
    "# 1. 购买的unique的I的月数量\n",
    "# 2. 购买的unique的B的月数量\n",
    "# 3. 购买的unique的C的月数量\n",
    "plu_ucounts_new_names = getMonthlyNames(\"up\", \"plu_ucounts\")\n",
    "bnd_ucounts_new_names = getMonthlyNames(\"up\", \"bnd_ucount\")\n",
    "dpt_ucounts_new_names = getMonthlyNames(\"up\", \"dpt_ucounts\")\n",
    "user_profile_dict[\"up_monthly_plu_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\"], \"pluno\", plu_ucounts_new_names, True)\n",
    "user_profile_dict[\"up_monthly_bnd_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\"], \"bndno\", bnd_ucounts_new_names, True)\n",
    "user_profile_dict[\"up_monthly_dpt_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\"], \"dptno\", dpt_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "user_profile_dict[\"up_monthly_plu_counts_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_plu_counts_df\"], [\"vipno\"], 1, \"up_monthly_plu_counts\")\n",
    "user_profile_dict[\"up_monthly_plu_sum_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_plu_sum_df\"], [\"vipno\"], 1, \"up_monthly_plu_sum\")\n",
    "user_profile_dict[\"up_monthly_plu_day_ucounts_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_plu_day_ucounts_df\"], [\"vipno\"], 1, \"up_monthly_plu_day_ucounts\")\n",
    "# 2. agg: TYPE.1 count/ratio - product diversity\n",
    "user_profile_dict[\"up_monthly_plu_ucounts_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_plu_ucounts_df\"], [\"vipno\"], 1, \"up_monthly_plu_ucounts\")\n",
    "user_profile_dict[\"up_monthly_bnd_ucounts_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_bnd_ucounts_df\"], [\"vipno\"], 1, \"up_monthly_bnd_ucounts\")\n",
    "user_profile_dict[\"up_monthly_dpt_ucounts_agg_df\"] = getMonthAgg(user_profile_dict[\"up_monthly_dpt_ucounts_df\"], [\"vipno\"], 1, \"up_monthly_dpt_ucounts\")\n",
    "\n",
    "#\n",
    "# TYPE.2 AGG feature - brand/category/item AGG 衡量用户的购买习惯\n",
    "# 每组内先针对单个B、C、I进行统计，再进行aggregation 针对B、C、I统计\n",
    "# 1. 总时间内发生被购买的天数\n",
    "# 2. 总时间内被购买的次数\n",
    "# 3. 总时间被购买的金额getUIBCAgg(feature_extract_df, [\"pluno\", \"vipno\"], \"pluno\", \"id\", 2, \"pp_plu_user_agg_counts\", 0)\n",
    "# agg操作包含mean、std、max、median pp_plu_user_agg_counts_df\n",
    "# plu\n",
    "user_profile_dict[\"up_u_plu_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"pluno\"], \"vipno\", \"id\", 2, \"up_u_plu_agg_counts\", 0)\n",
    "user_profile_dict[\"up_u_plu_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"pluno\"], \"vipno\", \"amt\", 2, \"up_u_plu_agg_sum\", 2)\n",
    "user_profile_dict[\"up_u_plu_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"pluno\"], \"vipno\", \"just_date\", 2, \"up_u_plu_agg_day_ucounts\", 1)\n",
    "# bnd\n",
    "user_profile_dict[\"up_u_bnd_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"bndno\"], \"vipno\", \"id\", 2, \"up_u_bnd_agg_counts\", 0)\n",
    "user_profile_dict[\"up_u_bnd_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"bndno\"], \"vipno\", \"amt\", 2, \"up_u_bnd_agg_sum\", 2)\n",
    "user_profile_dict[\"up_u_bnd_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"bndno\"], \"vipno\", \"just_date\", 2, \"up_u_bnd_agg_day_ucounts\", 1)\n",
    "# dpt\n",
    "user_profile_dict[\"up_u_dpt_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"dptno\"], \"vipno\", \"id\", 2, \"up_u_dpt_agg_counts\", 0)\n",
    "user_profile_dict[\"up_u_dpt_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"dptno\"], \"vipno\", \"amt\", 2, \"up_u_dpt_agg_sum\", 2)\n",
    "user_profile_dict[\"up_u_dpt_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"vipno\", \"dptno\"], \"vipno\", \"just_date\", 2, \"up_u_dpt_agg_day_ucounts\", 1)\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week（过去7天）\n",
    "# TYPE.1 count/ratio - count\n",
    "user_profile_dict[\"up_l_w_plu_counts_df\"] = getTotalCounts(last_week_df, [\"vipno\"], \"pluno\", \"up_l_w_plu_counts\", False)\n",
    "user_profile_dict[\"up_l_w_plu_sum_df\"] = getTotalSum(last_week_df, [\"vipno\"], \"amt\", \"up_l_w_plu_sum\")\n",
    "user_profile_dict[\"up_l_w_plu_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\"], \"just_date\", \"up_l_w_plu_day_ucounts\", True)\n",
    "# last week（过去7天）\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "user_profile_dict[\"up_l_w_plu_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\"], \"pluno\", \"up_l_w_plu_ucounts\", True)\n",
    "user_profile_dict[\"up_l_w_bnd_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\"], \"bndno\", \"up_l_w_bnd_ucounts\", True)\n",
    "user_profile_dict[\"up_l_w_dpt_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\"], \"dptno\", \"up_l_w_dpt_ucounts\", True)\n",
    "# last month 过去一个月\n",
    "# TYPE.1 count/ratio - count\n",
    "user_profile_dict[\"up_l_m_plu_counts_df\"] = getTotalCounts(last_month_df, [\"vipno\"], \"pluno\", \"up_l_m_plu_counts\", False)\n",
    "user_profile_dict[\"up_l_m_plu_sum_df\"] = getTotalSum(last_month_df, [\"vipno\"], \"amt\", \"up_l_m_plu_sum\")\n",
    "user_profile_dict[\"up_l_m_plu_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\"], \"just_date\", \"up_l_m_plu_day_ucounts\", True)\n",
    "# last month 过去一个月\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "user_profile_dict[\"up_l_m_plu_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\"], \"pluno\", \"up_l_m_plu_ucounts\", True)\n",
    "user_profile_dict[\"up_l_m_bnd_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\"], \"bndno\", \"up_l_m_bnd_ucounts\", True)\n",
    "user_profile_dict[\"up_l_m_dpt_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\"], \"dptno\", \"up_l_m_dpt_ucounts\", True)\n",
    "\n",
    "# \n",
    "# TYPE.4 complex feature - repeat feature\n",
    "#统计repeat {I, B, C}的count/ratio\n",
    "#1. count:被该用户重复购买过的商品的数量\n",
    "#2. ratio:count / 该用户购买过的商品总数\n",
    "user_profile_dict[\"up_repeat_plu_df\"] = getRepeatFeature(feature_extract_df, [\"vipno\", \"pluno\"], \"up_repeat_plu\")\n",
    "user_profile_dict[\"up_repeat_bnd_df\"] = getRepeatFeature(feature_extract_df, [\"vipno\", \"bndno\"], \"up_repeat_bnd\")\n",
    "user_profile_dict[\"up_repeat_dpt_df\"] = getRepeatFeature(feature_extract_df, [\"vipno\", \"dptno\"], \"up_repeat_dpt\")\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "user_profile_dict[\"up_monthly_plu_counts_df\"][\"up_trend_plu_counts\"] = user_profile_dict[\"up_monthly_plu_counts_df\"].apply(getTrend, axis=1)\n",
    "user_profile_dict[\"up_monthly_plu_sum_df\"][\"up_trend_plu_sum\"] = user_profile_dict[\"up_monthly_plu_sum_df\"].apply(getTrend, axis=1)\n",
    "user_profile_dict[\"up_monthly_plu_day_ucounts_df\"][\"up_trend_plu_day_ucounts\"] = user_profile_dict[\"up_monthly_plu_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "user_profile_dict[\"up_monthly_plu_ucounts_df\"][\"up_trend_plu_ucounts\"] = user_profile_dict[\"up_monthly_plu_ucounts_df\"].apply(getTrend, axis=1)\n",
    "user_profile_dict[\"up_monthly_bnd_ucounts_df\"][\"up_trend_bnd_ucounts\"] = user_profile_dict[\"up_monthly_bnd_ucounts_df\"].apply(getTrend, axis=1)\n",
    "user_profile_dict[\"up_monthly_dpt_ucounts_df\"][\"up_trend_dpt_ucounts\"] = user_profile_dict[\"up_monthly_dpt_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "user_profile_dict[\"up_bias_ratio_plu_count_df\"] = getDeviation(user_profile_dict[\"up_monthly_plu_counts_df\"], user_profile_dict[\"up_monthly_plu_counts_agg_df\"], [\"vipno\"], plu_monthly_counts_new_names, \"up_plu_counts\")\n",
    "user_profile_dict[\"up_bias_ratio_plu_sum_df\"] = getDeviation(user_profile_dict[\"up_monthly_plu_sum_df\"], user_profile_dict[\"up_monthly_plu_sum_agg_df\"], [\"vipno\"], plu_sum_new_names, \"up_plu_sum\")\n",
    "user_profile_dict[\"up_bias_ratio_plu_day_ucounts_df\"] = getDeviation(user_profile_dict[\"up_monthly_plu_day_ucounts_df\"], user_profile_dict[\"up_monthly_plu_day_ucounts_agg_df\"], [\"vipno\"], plu_day_ucounts_new_names, \"up_plu_day_ucounts\")\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "user_profile_dict[\"up_bias_ratio_plu_ucounts_df\"] =  getDeviation(user_profile_dict[\"up_monthly_plu_ucounts_df\"], user_profile_dict[\"up_monthly_plu_ucounts_agg_df\"], [\"vipno\"], plu_ucounts_new_names, \"up_plu_ucounts\")\n",
    "user_profile_dict[\"up_bias_ratio_bnd_ucounts_df\"] =  getDeviation(user_profile_dict[\"up_monthly_bnd_ucounts_df\"], user_profile_dict[\"up_monthly_bnd_ucounts_agg_df\"], [\"vipno\"], bnd_ucounts_new_names, \"up_bnd_ucounts\")\n",
    "user_profile_dict[\"up_bias_ratio_dpt_ucounts_df\"] =  getDeviation(user_profile_dict[\"up_monthly_dpt_ucounts_df\"], user_profile_dict[\"up_monthly_dpt_ucounts_agg_df\"], [\"vipno\"], dpt_ucounts_new_names, \"up_dpt_ucounts\")\n",
    "\n",
    "other_list = [\"up_l_w_plu_counts_df\", \"up_l_w_plu_sum_df\", \"up_l_w_plu_day_ucounts_df\",\n",
    "             \"up_l_w_plu_ucounts_df\", \"up_l_w_bnd_ucounts_df\", \"up_l_w_dpt_ucounts_df\",\n",
    "             \"up_l_m_plu_counts_df\", \"up_l_m_plu_sum_df\", \"up_l_m_plu_day_ucounts_df\",\n",
    "             \"up_l_m_plu_ucounts_df\", \"up_l_m_bnd_ucounts_df\", \"up_l_m_dpt_ucounts_df\"]\n",
    "user_profile_df = commonMergeDataFrame(user_profile_dict, other_list)\n",
    "assert isDifferent(feature_extract_df, [\"vipno\"], user_profile_df)\n",
    "user_profile_df.sort_values(\"vipno\").head()\n",
    "\n",
    "# user_profile_df.to_csv(\"./csv/user_profile.csv\")\n",
    "user_profile_dict[\"up_plu_counts_df\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-plu profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10981, 2)\n",
      "(10981, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vipno</th>\n",
       "      <th>pluno</th>\n",
       "      <th>upp_up_counts</th>\n",
       "      <th>upp_up_sum</th>\n",
       "      <th>upp_up_day_ucounts</th>\n",
       "      <th>upp_first_up_counts</th>\n",
       "      <th>upp_second_up_counts</th>\n",
       "      <th>upp_fourth_up_counts</th>\n",
       "      <th>upp_fifth_up_counts</th>\n",
       "      <th>upp_trend_up_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>upp_up_l_m_day_ucounts</th>\n",
       "      <th>upp_up_counts_bias</th>\n",
       "      <th>upp_up_counts_bias_divide_std</th>\n",
       "      <th>upp_up_counts_bias_divide_mean</th>\n",
       "      <th>upp_up_sum_bias</th>\n",
       "      <th>upp_up_sum_bias_divide_std</th>\n",
       "      <th>upp_up_sum_bias_divide_mean</th>\n",
       "      <th>upp_up_day_ucounts_bias</th>\n",
       "      <th>upp_up_day_ucounts_bias_divide_std</th>\n",
       "      <th>upp_up_day_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781924</td>\n",
       "      <td>10113009</td>\n",
       "      <td>1</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.266667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>781924</td>\n",
       "      <td>34023002</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>781924</td>\n",
       "      <td>23113024</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>781924</td>\n",
       "      <td>15202012</td>\n",
       "      <td>1</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.633333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>781924</td>\n",
       "      <td>15200007</td>\n",
       "      <td>3</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-33.733333</td>\n",
       "      <td>-6.350853</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vipno     pluno  upp_up_counts  upp_up_sum  upp_up_day_ucounts  \\\n",
       "0   781924  10113009              1    6.800000                   1   \n",
       "19  781924  34023002              1   15.000000                   1   \n",
       "18  781924  23113024              1   18.000000                   1   \n",
       "17  781924  15202012              1    4.900000                   1   \n",
       "16  781924  15200007              3  101.200000                   3   \n",
       "\n",
       "    upp_first_up_counts  upp_second_up_counts  upp_fourth_up_counts  \\\n",
       "0              0.000000              1.000000              0.000000   \n",
       "19             0.000000              0.000000              0.000000   \n",
       "18             0.000000              0.000000              0.000000   \n",
       "17             0.000000              0.000000              1.000000   \n",
       "16             1.000000              1.000000              1.000000   \n",
       "\n",
       "    upp_fifth_up_counts  upp_trend_up_counts  \\\n",
       "0              0.000000            -0.100000   \n",
       "19             1.000000             0.300000   \n",
       "18             1.000000             0.300000   \n",
       "17             0.000000             0.100000   \n",
       "16             0.000000            -0.300000   \n",
       "\n",
       "                   ...                   upp_up_l_m_day_ucounts  \\\n",
       "0                  ...                                 0.000000   \n",
       "19                 ...                                 1.000000   \n",
       "18                 ...                                 1.000000   \n",
       "17                 ...                                 0.000000   \n",
       "16                 ...                                 0.000000   \n",
       "\n",
       "    upp_up_counts_bias  upp_up_counts_bias_divide_std  \\\n",
       "0            -0.333333                      -0.577350   \n",
       "19            1.000000                       0.000000   \n",
       "18            1.000000                       0.000000   \n",
       "17           -0.333333                      -0.577350   \n",
       "16           -1.000000                       0.000000   \n",
       "\n",
       "    upp_up_counts_bias_divide_mean  upp_up_sum_bias  \\\n",
       "0                        -1.000000        -2.266667   \n",
       "19                        0.000000        15.000000   \n",
       "18                        0.000000        18.000000   \n",
       "17                       -1.000000        -1.633333   \n",
       "16                       -1.000000       -33.733333   \n",
       "\n",
       "    upp_up_sum_bias_divide_std  upp_up_sum_bias_divide_mean  \\\n",
       "0                    -0.577350                    -1.000000   \n",
       "19                    0.000000                     0.000000   \n",
       "18                    0.000000                     0.000000   \n",
       "17                   -0.577350                    -1.000000   \n",
       "16                   -6.350853                    -1.000000   \n",
       "\n",
       "    upp_up_day_ucounts_bias  upp_up_day_ucounts_bias_divide_std  \\\n",
       "0                 -0.333333                           -0.577350   \n",
       "19                 1.000000                            0.000000   \n",
       "18                 1.000000                            0.000000   \n",
       "17                -0.333333                           -0.577350   \n",
       "16                -1.000000                            0.000000   \n",
       "\n",
       "    upp_up_day_ucounts_bias_divide_mean  \n",
       "0                             -1.000000  \n",
       "19                             0.000000  \n",
       "18                             0.000000  \n",
       "17                            -1.000000  \n",
       "16                            -1.000000  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13794个UP对\n",
    "u_p_profile_dict = {}\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. U-P对总次数 使用id表示订单内重复购买某个商品也算是一次\n",
    "# 2. U-P对总金额\n",
    "# 3. U-P对总出现天数， 这里基本上和U-P对总次数差不多，因为同一天只有一个订单，并且一个订单同样的商品只有一个\n",
    "u_p_profile_dict[\"upp_up_counts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"pluno\"], \"id\", \"upp_up_counts\", False)\n",
    "u_p_profile_dict[\"upp_up_sum_df\"] = getTotalSum(feature_extract_df, [\"vipno\",\"pluno\"], \"amt\", \"upp_up_sum\")\n",
    "u_p_profile_dict[\"upp_up_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"pluno\"], \"just_date\", \"upp_up_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. U-P对月次数\n",
    "# 2. U-P对月金额\n",
    "# 3. U-P对月出现天数\n",
    "upp_monthly_up_counts_new_names = getMonthlyNames(\"upp\", \"up_counts\")\n",
    "upp_monthly_up_sum_new_names = getMonthlyNames(\"upp\", \"up_sum\")\n",
    "upp_monthly_up_day_ucounts_new_names = getMonthlyNames(\"upp\", \"up_day_ucounts\")\n",
    "u_p_profile_dict[\"upp_monthly_up_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\",\"pluno\"], \"id\", upp_monthly_up_counts_new_names, False)\n",
    "u_p_profile_dict[\"upp_monthly_up_sum_df\"] = getMonthlySum(feature_extract_df, [\"vipno\",\"pluno\"], \"amt\", upp_monthly_up_sum_new_names)\n",
    "u_p_profile_dict[\"upp_monthly_up_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\",\"pluno\"], \"just_date\", upp_monthly_up_day_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "u_p_profile_dict[\"upp_monthly_up_counts_agg_df\"] = getMonthAgg(u_p_profile_dict[\"upp_monthly_up_counts_df\"], [\"vipno\",\"pluno\"], 2, \"upp_monthly_up_counts\")\n",
    "u_p_profile_dict[\"upp_monthly_up_sum_agg_df\"] = getMonthAgg(u_p_profile_dict[\"upp_monthly_up_sum_df\"], [\"vipno\",\"pluno\"], 2, \"upp_monthly_up_sum\")\n",
    "u_p_profile_dict[\"upp_monthly_up_day_ucounts_agg_df\"] = getMonthAgg(u_p_profile_dict[\"upp_monthly_up_day_ucounts_df\"], [\"vipno\",\"pluno\"], 2, \"upp_monthly_up_day_ucounts\")\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week（过去7天）\n",
    "# TYPE.1 count/ratio - count\n",
    "u_p_profile_dict[\"upp_up_l_w_counts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"pluno\"], \"id\", \"upp_up_l_w_counts\", False)\n",
    "u_p_profile_dict[\"upp_up_l_w_sum_df\"] = getTotalSum(last_week_df, [\"vipno\",\"pluno\"], \"amt\", \"upp_up_l_w_sum\")\n",
    "u_p_profile_dict[\"upp_up_l_w_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"pluno\"], \"just_date\", \"upp_up_l_w_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "u_p_profile_dict[\"upp_up_l_m_counts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"pluno\"], \"id\", \"upp_up_l_m_counts\", False)\n",
    "u_p_profile_dict[\"upp_up_l_m_sum_df\"] = getTotalSum(last_month_df, [\"vipno\",\"pluno\"], \"amt\", \"upp_up_l_m_sum\")\n",
    "u_p_profile_dict[\"upp_up_l_m_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"pluno\"], \"just_date\", \"upp_up_l_m_day_ucounts\", True)\n",
    "\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "u_p_profile_dict[\"upp_monthly_up_counts_df\"][\"upp_trend_up_counts\"] = u_p_profile_dict[\"upp_monthly_up_counts_df\"].apply(getTrend, axis=1)\n",
    "u_p_profile_dict[\"upp_monthly_up_sum_df\"][\"upp_trend_up_sum\"] = u_p_profile_dict[\"upp_monthly_up_sum_df\"].apply(getTrend, axis=1)\n",
    "u_p_profile_dict[\"upp_monthly_up_day_ucounts_df\"][\"upp_trend_up_day_ucounts\"] =u_p_profile_dict[\"upp_monthly_up_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "u_p_profile_dict[\"upp_bias_ratio_up_counts_df\"] = getDeviation(u_p_profile_dict[\"upp_monthly_up_counts_df\"], u_p_profile_dict[\"upp_monthly_up_counts_agg_df\"], [\"vipno\",\"pluno\"], upp_monthly_up_counts_new_names, \"upp_up_counts\")\n",
    "u_p_profile_dict[\"upp_bias_ratio_up_sum_df\"] = getDeviation(u_p_profile_dict[\"upp_monthly_up_sum_df\"], u_p_profile_dict[\"upp_monthly_up_sum_agg_df\"], [\"vipno\",\"pluno\"], upp_monthly_up_sum_new_names, \"upp_up_sum\")\n",
    "u_p_profile_dict[\"upp_bias_ratio_up_day_ucounts_df\"] = getDeviation(u_p_profile_dict[\"upp_monthly_up_day_ucounts_df\"], u_p_profile_dict[\"upp_monthly_up_day_ucounts_agg_df\"], [\"vipno\",\"pluno\"], upp_monthly_up_day_ucounts_new_names, \"upp_up_day_ucounts\")\n",
    "\n",
    "upp_other_list = [\"upp_up_l_w_counts_df\", \"upp_up_l_w_sum_df\", \"upp_up_l_w_day_ucounts_df\",\n",
    "                 \"upp_up_l_m_counts_df\", \"upp_up_l_m_sum_df\", \"upp_up_l_m_day_ucounts_df\"]\n",
    "u_p_profile_df = commonMergeDataFrame(u_p_profile_dict, upp_other_list)\n",
    "assert isDifferent(feature_extract_df, [\"vipno\",\"pluno\"], u_p_profile_df)\n",
    "u_p_profile_df.sort_values(\"vipno\").head()\n",
    "\n",
    "# user_profile_df.to_csv(\"./csv/u_p_profile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-bnd profile -1代表三无产品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5339, 2)\n",
      "(5339, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vipno</th>\n",
       "      <th>bndno</th>\n",
       "      <th>ubp_ub_counts</th>\n",
       "      <th>ubp_ub_sum</th>\n",
       "      <th>ubp_ub_day_ucounts</th>\n",
       "      <th>ubp_first_ub_counts</th>\n",
       "      <th>ubp_second_ub_counts</th>\n",
       "      <th>ubp_fourth_ub_counts</th>\n",
       "      <th>ubp_fifth_ub_counts</th>\n",
       "      <th>ubp_trend_ub_counts_df</th>\n",
       "      <th>...</th>\n",
       "      <th>ubp_ub_l_m_day_ucounts</th>\n",
       "      <th>ubp_ub_counts_bias</th>\n",
       "      <th>ubp_ub_counts_bias_divide_std</th>\n",
       "      <th>ubp_ub_counts_bias_divide_mean</th>\n",
       "      <th>ubp_ub_sum_bias</th>\n",
       "      <th>ubp_ub_sum_bias_divide_std</th>\n",
       "      <th>ubp_ub_sum_bias_divide_mean</th>\n",
       "      <th>ubp_ub_day_ucounts_bias</th>\n",
       "      <th>ubp_ub_day_ucounts_bias_divide_std</th>\n",
       "      <th>ubp_ub_day_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781924</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>73.720000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.573333</td>\n",
       "      <td>-0.024452</td>\n",
       "      <td>-0.030869</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>781924</td>\n",
       "      <td>10106.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>781924</td>\n",
       "      <td>10706.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.266667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781924</td>\n",
       "      <td>11129.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>781924</td>\n",
       "      <td>11149.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    vipno        bndno  ubp_ub_counts  ubp_ub_sum  ubp_ub_day_ucounts  \\\n",
       "0  781924    -1.000000              5   73.720000                   3   \n",
       "1  781924 10106.000000              1    5.500000                   1   \n",
       "2  781924 10706.000000              1    6.800000                   1   \n",
       "3  781924 11129.000000              1    9.900000                   1   \n",
       "4  781924 11149.000000              1   15.600000                   1   \n",
       "\n",
       "   ubp_first_ub_counts  ubp_second_ub_counts  ubp_fourth_ub_counts  \\\n",
       "0             1.000000              3.000000              0.000000   \n",
       "1             1.000000              0.000000              0.000000   \n",
       "2             0.000000              1.000000              0.000000   \n",
       "3             1.000000              0.000000              0.000000   \n",
       "4             1.000000              0.000000              0.000000   \n",
       "\n",
       "   ubp_fifth_ub_counts  ubp_trend_ub_counts_df  \\\n",
       "0             1.000000               -0.300000   \n",
       "1             0.000000               -0.300000   \n",
       "2             0.000000               -0.100000   \n",
       "3             0.000000               -0.300000   \n",
       "4             0.000000               -0.300000   \n",
       "\n",
       "                  ...                   ubp_ub_l_m_day_ucounts  \\\n",
       "0                 ...                                 1.000000   \n",
       "1                 ...                                 0.000000   \n",
       "2                 ...                                 0.000000   \n",
       "3                 ...                                 0.000000   \n",
       "4                 ...                                 0.000000   \n",
       "\n",
       "   ubp_ub_counts_bias  ubp_ub_counts_bias_divide_std  \\\n",
       "0           -0.333333                      -0.218218   \n",
       "1           -0.333333                      -0.577350   \n",
       "2           -0.333333                      -0.577350   \n",
       "3           -0.333333                      -0.577350   \n",
       "4           -0.333333                      -0.577350   \n",
       "\n",
       "   ubp_ub_counts_bias_divide_mean  ubp_ub_sum_bias  \\\n",
       "0                       -0.250000        -0.573333   \n",
       "1                       -1.000000        -1.833333   \n",
       "2                       -1.000000        -2.266667   \n",
       "3                       -1.000000        -3.300000   \n",
       "4                       -1.000000        -5.200000   \n",
       "\n",
       "   ubp_ub_sum_bias_divide_std  ubp_ub_sum_bias_divide_mean  \\\n",
       "0                   -0.024452                    -0.030869   \n",
       "1                   -0.577350                    -1.000000   \n",
       "2                   -0.577350                    -1.000000   \n",
       "3                   -0.577350                    -1.000000   \n",
       "4                   -0.577350                    -1.000000   \n",
       "\n",
       "   ubp_ub_day_ucounts_bias  ubp_ub_day_ucounts_bias_divide_std  \\\n",
       "0                 0.333333                            0.577350   \n",
       "1                -0.333333                           -0.577350   \n",
       "2                -0.333333                           -0.577350   \n",
       "3                -0.333333                           -0.577350   \n",
       "4                -0.333333                           -0.577350   \n",
       "\n",
       "   ubp_ub_day_ucounts_bias_divide_mean  \n",
       "0                             0.500000  \n",
       "1                            -1.000000  \n",
       "2                            -1.000000  \n",
       "3                            -1.000000  \n",
       "4                            -1.000000  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6446个UB对\n",
    "u_b_profile_dict = {}\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. U-B对总次数 使用id表示订单内重复购买某个商品也算是一次\n",
    "# 2. U-B总金额\n",
    "# 3. U-B对总出现天数, 与UP不同的是，虽然同一天只有一个订单，同一个订单里相同的商品只有一项，但相同品牌却容易出现多项\n",
    "u_b_profile_dict[\"ubp_ub_counts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"bndno\"], \"id\", \"ubp_ub_counts\", False)\n",
    "u_b_profile_dict[\"ubp_ub_sum_df\"] = getTotalSum(feature_extract_df, [\"vipno\",\"bndno\"], \"amt\", \"ubp_ub_sum\")\n",
    "u_b_profile_dict[\"ubp_ub_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"bndno\"], \"just_date\", \"ubp_ub_day_ucounts\", True)\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. 购买(主体为用户)/被购买(主体为B、C、I)的次数\n",
    "# 2. 购买(主体为用户)/被购买(主体为B、C、I)的金额\n",
    "# 3. 购买/被购买发生的天数\n",
    "ubp_monthly_ub_counts_new_names = getMonthlyNames(\"ubp\", \"ub_counts\")\n",
    "ubp_monthly_ub_sum_new_names = getMonthlyNames(\"ubp\", \"ub_sum\")\n",
    "ubp_monthly_ub_day_ucounts_new_names = getMonthlyNames(\"ubp\", \"ub_day_ucounts\")\n",
    "u_b_profile_dict[\"ubp_monthly_ub_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\",\"bndno\"], \"id\", ubp_monthly_ub_counts_new_names, False)\n",
    "u_b_profile_dict[\"ubp_monthly_ub_sum_df\"] = getMonthlySum(feature_extract_df, [\"vipno\",\"bndno\"], \"amt\", ubp_monthly_ub_sum_new_names)\n",
    "u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_df\"] =  getMonthlyCounts(feature_extract_df, [\"vipno\",\"bndno\"], \"just_date\", ubp_monthly_ub_day_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "u_b_profile_dict[\"ubp_monthly_ub_counts_agg_df\"] = getMonthAgg(u_b_profile_dict[\"ubp_monthly_ub_counts_df\"], [\"vipno\",\"bndno\"], 2, \"ubp_monthly_ub_counts\")\n",
    "u_b_profile_dict[\"ubp_monthly_ub_sum_agg_df\"] = getMonthAgg(u_b_profile_dict[\"ubp_monthly_ub_sum_df\"], [\"vipno\",\"bndno\"], 2, \"ubp_monthly_ub_sum\")\n",
    "u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_agg_df\"]  = getMonthAgg(u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_df\"], [\"vipno\",\"bndno\"], 2, \"ubp_monthly_ub_day_ucounts\")\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week\n",
    "# TYPE.1 count/ratio - count\n",
    "u_b_profile_dict[\"ubp_ub_l_w_counts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"bndno\"], \"id\", \"ubp_ub_l_w_counts\", False)\n",
    "u_b_profile_dict[\"ubp_ub_l_w_sum_df\"] = getTotalSum(last_week_df, [\"vipno\",\"bndno\"], \"amt\", \"ubp_ub_l_w_sum\")\n",
    "u_b_profile_dict[\"ubp_ub_l_w_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"bndno\"], \"just_date\", \"ubp_ub_l_w_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "u_b_profile_dict[\"ubp_ub_l_m_counts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"bndno\"], \"id\", \"ubp_ub_l_m_counts\", False)\n",
    "u_b_profile_dict[\"ubp_ub_l_m_sum_df\"] = getTotalSum(last_month_df, [\"vipno\",\"bndno\"], \"amt\", \"ubp_ub_l_m_sum\")\n",
    "u_b_profile_dict[\"ubp_ub_l_m_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"bndno\"], \"just_date\", \"ubp_ub_l_m_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "u_b_profile_dict[\"ubp_monthly_ub_counts_df\"][\"ubp_trend_ub_counts_df\"] = u_b_profile_dict[\"ubp_monthly_ub_counts_df\"].apply(getTrend, axis=1)\n",
    "u_b_profile_dict[\"ubp_monthly_ub_sum_df\"][\"ubp_trend_ub_sum_df\"] = u_b_profile_dict[\"ubp_monthly_ub_sum_df\"].apply(getTrend, axis=1)\n",
    "u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_df\"][\"ubp_trend_ub_day_ucounts_df\"] =  u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "u_b_profile_dict[\"ubp_bias_ratio_ub_counts_df\"] = getDeviation(u_b_profile_dict[\"ubp_monthly_ub_counts_df\"],u_b_profile_dict[\"ubp_monthly_ub_counts_agg_df\"], [\"vipno\",\"bndno\"], ubp_monthly_ub_counts_new_names, \"ubp_ub_counts\")\n",
    "u_b_profile_dict[\"ubp_bias_ratio_ub_sum_df\"] = getDeviation(u_b_profile_dict[\"ubp_monthly_ub_sum_df\"], u_b_profile_dict[\"ubp_monthly_ub_sum_agg_df\"], [\"vipno\",\"bndno\"], ubp_monthly_ub_sum_new_names, \"ubp_ub_sum\")\n",
    "u_b_profile_dict[\"ubp_bias_ratio_ub_day_ucounts_df\"] = getDeviation(u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_df\"], u_b_profile_dict[\"ubp_monthly_ub_day_ucounts_agg_df\"], [\"vipno\",\"bndno\"], ubp_monthly_ub_day_ucounts_new_names, \"ubp_ub_day_ucounts\")\n",
    "\n",
    "\n",
    "ubp_other_list = [\"ubp_ub_l_w_counts_df\", \"ubp_ub_l_w_sum_df\", \"ubp_ub_l_w_day_ucounts_df\", \n",
    "                 \"ubp_ub_l_m_counts_df\", \"ubp_ub_l_m_sum_df\", \"ubp_ub_l_m_day_ucounts_df\"]\n",
    "u_b_profile_df = commonMergeDataFrame(u_b_profile_dict, ubp_other_list)\n",
    "assert isDifferent(feature_extract_df, [\"vipno\",\"bndno\"], u_b_profile_df)\n",
    "u_b_profile_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-dpt profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8804, 2)\n",
      "(8804, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vipno</th>\n",
       "      <th>dptno</th>\n",
       "      <th>udp_ud_counts</th>\n",
       "      <th>udp_ud_sum</th>\n",
       "      <th>udp_ud_day_ucounts</th>\n",
       "      <th>udp_first_ud_counts</th>\n",
       "      <th>udp_second_ud_counts</th>\n",
       "      <th>udp_fourth_ud_counts</th>\n",
       "      <th>udp_fifth_ud_counts</th>\n",
       "      <th>udp_trend_ud_counts_df</th>\n",
       "      <th>...</th>\n",
       "      <th>udp_ud_l_m_day_ucounts</th>\n",
       "      <th>udp_ud_counts_bias</th>\n",
       "      <th>udp_ud_counts_bias_divide_std</th>\n",
       "      <th>udp_ud_counts_bias_divide_mean</th>\n",
       "      <th>udp_ud_sum_bias</th>\n",
       "      <th>udp_ud_sum_bias_divide_std</th>\n",
       "      <th>udp_ud_sum_bias_divide_mean</th>\n",
       "      <th>udp_ud_day_ucounts_bias</th>\n",
       "      <th>udp_ud_day_ucounts_bias_divide_std</th>\n",
       "      <th>udp_ud_day_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781924</td>\n",
       "      <td>10113</td>\n",
       "      <td>1</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.266667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>781924</td>\n",
       "      <td>10130</td>\n",
       "      <td>1</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>781924</td>\n",
       "      <td>11302</td>\n",
       "      <td>1</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781924</td>\n",
       "      <td>11531</td>\n",
       "      <td>1</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.200000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>781924</td>\n",
       "      <td>11532</td>\n",
       "      <td>2</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-1.154701</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-4.466667</td>\n",
       "      <td>-0.889722</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-1.154701</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    vipno  dptno  udp_ud_counts  udp_ud_sum  udp_ud_day_ucounts  \\\n",
       "0  781924  10113              1    6.800000                   1   \n",
       "1  781924  10130              1    5.500000                   1   \n",
       "2  781924  11302              1   10.800000                   1   \n",
       "3  781924  11531              1   15.600000                   1   \n",
       "4  781924  11532              2   13.400000                   2   \n",
       "\n",
       "   udp_first_ud_counts  udp_second_ud_counts  udp_fourth_ud_counts  \\\n",
       "0             0.000000              1.000000              0.000000   \n",
       "1             1.000000              0.000000              0.000000   \n",
       "2             0.000000              0.000000              0.000000   \n",
       "3             1.000000              0.000000              0.000000   \n",
       "4             1.000000              0.000000              1.000000   \n",
       "\n",
       "   udp_fifth_ud_counts  udp_trend_ud_counts_df  \\\n",
       "0             0.000000               -0.100000   \n",
       "1             0.000000               -0.300000   \n",
       "2             1.000000                0.300000   \n",
       "3             0.000000               -0.300000   \n",
       "4             0.000000               -0.200000   \n",
       "\n",
       "                  ...                   udp_ud_l_m_day_ucounts  \\\n",
       "0                 ...                                 0.000000   \n",
       "1                 ...                                 0.000000   \n",
       "2                 ...                                 1.000000   \n",
       "3                 ...                                 0.000000   \n",
       "4                 ...                                 0.000000   \n",
       "\n",
       "   udp_ud_counts_bias  udp_ud_counts_bias_divide_std  \\\n",
       "0           -0.333333                      -0.577350   \n",
       "1           -0.333333                      -0.577350   \n",
       "2            1.000000                       0.000000   \n",
       "3           -0.333333                      -0.577350   \n",
       "4           -0.666667                      -1.154701   \n",
       "\n",
       "   udp_ud_counts_bias_divide_mean  udp_ud_sum_bias  \\\n",
       "0                       -1.000000        -2.266667   \n",
       "1                       -1.000000        -1.833333   \n",
       "2                        0.000000        10.800000   \n",
       "3                       -1.000000        -5.200000   \n",
       "4                       -1.000000        -4.466667   \n",
       "\n",
       "   udp_ud_sum_bias_divide_std  udp_ud_sum_bias_divide_mean  \\\n",
       "0                   -0.577350                    -1.000000   \n",
       "1                   -0.577350                    -1.000000   \n",
       "2                    0.000000                     0.000000   \n",
       "3                   -0.577350                    -1.000000   \n",
       "4                   -0.889722                    -1.000000   \n",
       "\n",
       "   udp_ud_day_ucounts_bias  udp_ud_day_ucounts_bias_divide_std  \\\n",
       "0                -0.333333                           -0.577350   \n",
       "1                -0.333333                           -0.577350   \n",
       "2                 1.000000                            0.000000   \n",
       "3                -0.333333                           -0.577350   \n",
       "4                -0.666667                           -1.154701   \n",
       "\n",
       "   udp_ud_day_ucounts_bias_divide_mean  \n",
       "0                            -1.000000  \n",
       "1                            -1.000000  \n",
       "2                             0.000000  \n",
       "3                            -1.000000  \n",
       "4                            -1.000000  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10845个UD对\n",
    "u_d_profile_dict = {}\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. U-D对总次数\n",
    "# 2. U-D对总金额\n",
    "# 3. U-D对总出现天数\n",
    "u_d_profile_dict[\"udp_ud_counts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"dptno\"], \"id\", \"udp_ud_counts\", False)\n",
    "u_d_profile_dict[\"udp_ud_sum_df\"] = getTotalSum(feature_extract_df, [\"vipno\",\"dptno\"], \"amt\", \"udp_ud_sum\")\n",
    "u_d_profile_dict[\"udp_ud_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"vipno\",\"dptno\"], \"just_date\", \"udp_ud_day_ucounts\", True)\n",
    "\n",
    "# \n",
    "# TYPE.1 count/ratio - count\n",
    "# Monthly\n",
    "# 1. U-D对月次数\n",
    "# 2. U-D对月金额\n",
    "# 3. U-D对月出现天数\n",
    "udp_monthly_ud_counts_new_names = getMonthlyNames(\"udp\", \"ud_counts\")\n",
    "udp_monthly_ud_sum_new_names = getMonthlyNames(\"udp\", \"ud_sum\")\n",
    "udp_monthly_ud_day_ucounts_new_names = getMonthlyNames(\"udp\", \"ud_day_ucounts\")\n",
    "u_d_profile_dict[\"udp_monthly_ud_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\",\"dptno\"], \"id\", udp_monthly_ud_counts_new_names, False)\n",
    "u_d_profile_dict[\"udp_monthly_ud_sum_df\"] = getMonthlySum(feature_extract_df, [\"vipno\",\"dptno\"], \"amt\", udp_monthly_ud_sum_new_names)\n",
    "u_d_profile_dict[\"udp_monthly_ud_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"vipno\",\"dptno\"], \"just_date\", udp_monthly_ud_day_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "u_d_profile_dict[\"udp_monthly_ud_counts_agg_df\"] = getMonthAgg(u_d_profile_dict[\"udp_monthly_ud_counts_df\"], [\"vipno\",\"dptno\"], 2, \"udp_monthly_ud_counts\")\n",
    "u_d_profile_dict[\"udp_monthly_ud_sum_agg_df\"] = getMonthAgg(u_d_profile_dict[\"udp_monthly_ud_sum_df\"], [\"vipno\",\"dptno\"], 2, \"udp_monthly_ud_sum\")\n",
    "u_d_profile_dict[\"udp_monthly_ud_day_ucounts_agg_df\"] = getMonthAgg(u_d_profile_dict[\"udp_monthly_ud_day_ucounts_df\"], [\"vipno\",\"dptno\"], 2, \"udp_monthly_ud_day_ucounts\")\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week\n",
    "# TYPE.1 count/ratio - count\n",
    "u_d_profile_dict[\"udp_ud_l_w_counts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"dptno\"], \"id\", \"udp_ud_l_w_counts\", False)\n",
    "u_d_profile_dict[\"udp_ud_l_w_sum_df\"] = getTotalSum(last_week_df, [\"vipno\",\"dptno\"], \"amt\", \"udp_ud_l_w_sum\")\n",
    "u_d_profile_dict[\"udp_ud_l_w_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"vipno\",\"dptno\"], \"just_date\", \"udp_ud_l_w_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "u_d_profile_dict[\"udp_ud_l_m_counts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"dptno\"], \"id\", \"udp_ud_l_m_counts\", False)\n",
    "u_d_profile_dict[\"udp_ud_l_m_sum_df\"] = getTotalSum(last_month_df, [\"vipno\",\"dptno\"], \"amt\", \"udp_ud_l_m_sum\")\n",
    "u_d_profile_dict[\"udp_ud_l_m_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"vipno\",\"dptno\"], \"just_date\", \"udp_ud_l_m_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "u_d_profile_dict[\"udp_monthly_ud_counts_df\"][\"udp_trend_ud_counts_df\"] = u_d_profile_dict[\"udp_monthly_ud_counts_df\"].apply(getTrend, axis=1)\n",
    "u_d_profile_dict[\"udp_monthly_ud_sum_df\"][\"udp_trend_ud_sum_df\"] = u_d_profile_dict[\"udp_monthly_ud_sum_df\"].apply(getTrend, axis=1)\n",
    "u_d_profile_dict[\"udp_monthly_ud_day_ucounts_df\"][\"udp_trend_ud_day_ucounts_df\"] = u_d_profile_dict[\"udp_monthly_ud_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "u_d_profile_dict[\"udp_bias_ratio_ud_counts_df\"] = getDeviation(u_d_profile_dict[\"udp_monthly_ud_counts_df\"],u_d_profile_dict[\"udp_monthly_ud_counts_agg_df\"], [\"vipno\",\"dptno\"], udp_monthly_ud_counts_new_names, \"udp_ud_counts\")\n",
    "u_d_profile_dict[\"udp_bias_ratio_ud_sum_df\"] = getDeviation(u_d_profile_dict[\"udp_monthly_ud_sum_df\"], u_d_profile_dict[\"udp_monthly_ud_sum_agg_df\"], [\"vipno\",\"dptno\"], udp_monthly_ud_sum_new_names, \"udp_ud_sum\")\n",
    "u_d_profile_dict[\"udp_bias_ratio_ud_day_ucounts_df\"] = getDeviation(u_d_profile_dict[\"udp_monthly_ud_day_ucounts_df\"], u_d_profile_dict[\"udp_monthly_ud_day_ucounts_agg_df\"], [\"vipno\",\"dptno\"], udp_monthly_ud_day_ucounts_new_names, \"udp_ud_day_ucounts\")\n",
    "\n",
    "\n",
    "\n",
    "udp_other_list = [\"udp_ud_l_w_counts_df\", \"udp_ud_l_w_sum_df\", \"udp_ud_l_w_day_ucounts_df\",\n",
    "                 \"udp_ud_l_m_counts_df\", \"udp_ud_l_m_sum_df\", \"udp_ud_l_m_day_ucounts_df\"]\n",
    "u_d_profile_df = commonMergeDataFrame(u_d_profile_dict, udp_other_list)\n",
    "assert isDifferent(feature_extract_df, [\"vipno\",\"dptno\"], u_d_profile_df)\n",
    "u_d_profile_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plu profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3968, 1)\n",
      "(3968, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluno</th>\n",
       "      <th>pp_p_purchased_counts</th>\n",
       "      <th>pp_p_purchased_sum</th>\n",
       "      <th>pp_p_purchased_day_ucounts</th>\n",
       "      <th>pp_first_p_purchased_counts</th>\n",
       "      <th>pp_second_p_purchased_counts</th>\n",
       "      <th>pp_fourth_p_purchased_counts</th>\n",
       "      <th>pp_fifth_p_purchased_counts</th>\n",
       "      <th>pp_trend_p_purchased_counts_df</th>\n",
       "      <th>pp_first_p_purchased_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>pp_p_purchased_counts_bias_divide_mean</th>\n",
       "      <th>pp_p_purchased_sum_bias</th>\n",
       "      <th>pp_p_purchased_sum_bias_divide_std</th>\n",
       "      <th>pp_p_purchased_sum_bias_divide_mean</th>\n",
       "      <th>pp_p_purchased_day_ucounts_bias</th>\n",
       "      <th>pp_p_purchased_day_ucounts_bias_divide_std</th>\n",
       "      <th>pp_p_purchased_day_ucounts_bias_divide_mean</th>\n",
       "      <th>pp_p_has_u_ucounts_bias</th>\n",
       "      <th>pp_p_has_u_ucounts_bias_divide_std</th>\n",
       "      <th>pp_p_has_u_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.600000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000003</td>\n",
       "      <td>1</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000004</td>\n",
       "      <td>6</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-3.866667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000005</td>\n",
       "      <td>4</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000006</td>\n",
       "      <td>20</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>-7.200000</td>\n",
       "      <td>-0.704361</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.154701</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pluno  pp_p_purchased_counts  pp_p_purchased_sum  \\\n",
       "0  10000000                      1           10.800000   \n",
       "1  10000003                      1            5.900000   \n",
       "2  10000004                      6           34.800000   \n",
       "3  10000005                      4            8.000000   \n",
       "4  10000006                     20           54.000000   \n",
       "\n",
       "   pp_p_purchased_day_ucounts  pp_first_p_purchased_counts  \\\n",
       "0                           1                     0.000000   \n",
       "1                           1                     0.000000   \n",
       "2                           6                     1.000000   \n",
       "3                           4                     0.000000   \n",
       "4                          15                    10.000000   \n",
       "\n",
       "   pp_second_p_purchased_counts  pp_fourth_p_purchased_counts  \\\n",
       "0                      0.000000                      1.000000   \n",
       "1                      0.000000                      0.000000   \n",
       "2                      3.000000                      1.000000   \n",
       "3                      2.000000                      1.000000   \n",
       "4                      4.000000                      3.000000   \n",
       "\n",
       "   pp_fifth_p_purchased_counts  pp_trend_p_purchased_counts_df  \\\n",
       "0                     0.000000                        0.100000   \n",
       "1                     1.000000                        0.300000   \n",
       "2                     1.000000                       -0.200000   \n",
       "3                     1.000000                        0.200000   \n",
       "4                     3.000000                       -2.200000   \n",
       "\n",
       "   pp_first_p_purchased_sum                 ...                   \\\n",
       "0                  0.000000                 ...                    \n",
       "1                  0.000000                 ...                    \n",
       "2                  5.800000                 ...                    \n",
       "3                  0.000000                 ...                    \n",
       "4                 27.000000                 ...                    \n",
       "\n",
       "   pp_p_purchased_counts_bias_divide_mean  pp_p_purchased_sum_bias  \\\n",
       "0                               -1.000000                -3.600000   \n",
       "1                                0.000000                 5.900000   \n",
       "2                               -0.400000                -3.866667   \n",
       "3                                0.000000                 0.000000   \n",
       "4                               -0.470588                -7.200000   \n",
       "\n",
       "   pp_p_purchased_sum_bias_divide_std  pp_p_purchased_sum_bias_divide_mean  \\\n",
       "0                           -0.577350                            -1.000000   \n",
       "1                            0.000000                             0.000000   \n",
       "2                           -0.577350                            -0.400000   \n",
       "3                            0.000000                             0.000000   \n",
       "4                           -0.704361                            -0.470588   \n",
       "\n",
       "   pp_p_purchased_day_ucounts_bias  \\\n",
       "0                        -0.333333   \n",
       "1                         1.000000   \n",
       "2                        -0.666667   \n",
       "3                         0.000000   \n",
       "4                        -1.000000   \n",
       "\n",
       "   pp_p_purchased_day_ucounts_bias_divide_std  \\\n",
       "0                                   -0.577350   \n",
       "1                                    0.000000   \n",
       "2                                   -0.577350   \n",
       "3                                    0.000000   \n",
       "4                                   -0.577350   \n",
       "\n",
       "   pp_p_purchased_day_ucounts_bias_divide_mean  pp_p_has_u_ucounts_bias  \\\n",
       "0                                    -1.000000                -0.333333   \n",
       "1                                     0.000000                 1.000000   \n",
       "2                                    -0.400000                -0.666667   \n",
       "3                                     0.000000                 0.000000   \n",
       "4                                    -0.250000                -2.000000   \n",
       "\n",
       "   pp_p_has_u_ucounts_bias_divide_std  pp_p_has_u_ucounts_bias_divide_mean  \n",
       "0                           -0.577350                            -1.000000  \n",
       "1                            0.000000                             0.000000  \n",
       "2                           -0.577350                            -0.400000  \n",
       "3                            0.000000                             0.000000  \n",
       "4                           -1.154701                            -0.500000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4674个商品\n",
    "plu_profile_dict = {}\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. plu被购买总次数\n",
    "# 2. plu被购买总金额\n",
    "# 3. plu 被购买的总天数(比plu被购买总次数少，因为可能一个商品会在同一天被购买多次)\n",
    "plu_profile_dict[\"pp_p_purchased_counts_df\"] = getTotalCounts(feature_extract_df, [\"pluno\"], \"id\", \"pp_p_purchased_counts\", False)\n",
    "plu_profile_dict[\"pp_p_purchased_sum_df\"] = getTotalSum(feature_extract_df, [\"pluno\"], \"amt\", \"pp_p_purchased_sum\")\n",
    "plu_profile_dict[\"pp_p_purchased_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"pluno\"], \"just_date\", \"pp_p_purchased_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. plu每月被购买次数\n",
    "# 2. plu每月被购买金额\n",
    "# 3. plu每月被购买天数\n",
    "pp_monthly_p_purchased_counts_new_names = getMonthlyNames(\"pp\", \"p_purchased_counts\")\n",
    "pp_monthly_p_purchased_sum_new_names = getMonthlyNames(\"pp\", \"p_purchased_sum\")\n",
    "pp_monthly_p_purchased_day_ucounts_new_names = getMonthlyNames(\"pp\", \"p_purchased_day_ucounts\")\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"pluno\"], \"id\", pp_monthly_p_purchased_counts_new_names, False)\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_sum_df\"] = getMonthlySum(feature_extract_df, [\"pluno\"], \"amt\", pp_monthly_p_purchased_sum_new_names)\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"pluno\"], \"just_date\", pp_monthly_p_purchased_day_ucounts_new_names, True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "# whold period\n",
    "# 1. 买过该品牌或品类或商品的不同的买家的人数\n",
    "plu_profile_dict[\"pp_p_has_u_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"pluno\"], \"vipno\", \"pp_p_has_u_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "# monthly\n",
    "# 1. 每月买过该品牌或品类或商品的不同的买家的人数\n",
    "pp_monthly_p_has_u_ucounts_new_names = getMonthlyNames(\"pp\", \"p_has_u_ucounts\")\n",
    "\n",
    "plu_profile_dict[\"pp_monthly_p_has_u_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"pluno\"], \"vipno\", pp_monthly_p_has_u_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_counts_agg_df\"] = getMonthAgg(plu_profile_dict[\"pp_monthly_p_purchased_counts_df\"], [\"pluno\"], 1, \"pp_monthly_p_purchased_counts\")\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_sum_agg_df\"] = getMonthAgg(plu_profile_dict[\"pp_monthly_p_purchased_sum_df\"], [\"pluno\"], 1, \"pp_monthly_p_purchased_sum\")\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_agg_df\"] = getMonthAgg(plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_df\"], [\"pluno\"], 1, \"pp_monthly_p_purchased_day_ucounts\")\n",
    "# 2. agg: TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "plu_profile_dict[\"pp_monthly_p_has_u_ucounts_agg_df\"] = getMonthAgg(plu_profile_dict[\"pp_monthly_p_has_u_ucounts_df\"], [\"pluno\"], 1, \"pp_monthly_p_has_u_ucounts\")\n",
    "\n",
    "# TYPE.2 AGG feature - user AGG\n",
    "# agg_type: 0 - count 1 - nunique 2 - sum\n",
    "plu_profile_dict[\"pp_plu_user_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"pluno\", \"vipno\"], \"pluno\", \"id\", 2, \"pp_plu_user_agg_counts\", 0)\n",
    "plu_profile_dict[\"pp_plu_user_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"pluno\", \"vipno\"], \"pluno\", \"amt\", 2, \"pp_plu_user_agg_sum\", 2)\n",
    "plu_profile_dict[\"pp_plu_user_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"pluno\", \"vipno\"], \"pluno\", \"just_date\", 2, \"pp_plu_user_agg_day_ucounts\", 1)\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week\n",
    "# TYPE.1 count/ratio - count\n",
    "plu_profile_dict[\"pp_p_l_w_purchased_counts_df\"] = getTotalCounts(last_week_df, [\"pluno\"], \"id\", \"pp_p_l_w_purchased_counts\", False)\n",
    "plu_profile_dict[\"pp_p_l_w_purchased_sum_df\"] = getTotalSum(last_week_df, [\"pluno\"], \"amt\", \"pp_p_l_w_purchased_sum\")\n",
    "plu_profile_dict[\"pp_p_l_w_purchased_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"pluno\"], \"just_date\", \"pp_p_l_w_purchased_day_ucounts\", True)\n",
    "# last week\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "plu_profile_dict[\"pp_p_l_w_has_u_ucounts_df\"] = getTotalCounts(last_week_df, [\"pluno\"], \"vipno\", \"pp_p_l_w_has_u_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "plu_profile_dict[\"pp_p_l_m_purchased_counts_df\"] = getTotalCounts(last_month_df, [\"pluno\"], \"id\", \"pp_p_l_m_purchased_counts\", False)\n",
    "plu_profile_dict[\"pp_p_l_m_purchased_sum_df\"] = getTotalSum(last_month_df, [\"pluno\"], \"amt\", \"pp_p_l_m_purchased_sum\")\n",
    "plu_profile_dict[\"pp_p_l_m_purchased_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"pluno\"], \"just_date\", \"pp_p_l_m_purchased_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "plu_profile_dict[\"pp_p_l_m_has_u_ucounts_df\"] = getTotalCounts(last_month_df, [\"pluno\"], \"vipno\", \"pp_p_l_m_has_u_ucounts\", True)\n",
    "\n",
    "\n",
    "# \n",
    "# TYPE.4 complex feature - repeat feature\n",
    "# 统计repeat buyer的count/ratio\n",
    "# 1. count:至少两天购买同一I或B或C的人数\n",
    "# 2. ratio:count / 购买该I或B或C的总人数\n",
    "plu_profile_dict[\"pp_plu_repeat_buyer_df\"] = getRepeatFeature(feature_extract_df, [\"pluno\", \"vipno\"], \"pp_plu_repeat_buyer\")\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_counts_df\"][\"pp_trend_p_purchased_counts_df\"] = plu_profile_dict[\"pp_monthly_p_purchased_counts_df\"].apply(getTrend, axis=1)\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_sum_df\"][\"pp_trend_p_purchased_sum_df\"] = plu_profile_dict[\"pp_monthly_p_purchased_sum_df\"].apply(getTrend, axis=1)\n",
    "plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_df\"][\"pp_trend_p_purchased_day_ucounts_df\"] = plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "plu_profile_dict[\"pp_monthly_p_has_u_ucounts_df\"][\"pp_trend_p_has_u_ucounts_df\"] = plu_profile_dict[\"pp_monthly_p_has_u_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "plu_profile_dict[\"pp_bias_ratio_p_purchased_counts_df\"] = getDeviation(plu_profile_dict[\"pp_monthly_p_purchased_counts_df\"],plu_profile_dict[\"pp_monthly_p_purchased_counts_agg_df\"], [\"pluno\"], pp_monthly_p_purchased_counts_new_names, \"pp_p_purchased_counts\")\n",
    "plu_profile_dict[\"pp_bias_ratio_p_purchased_sum_df\"] = getDeviation(plu_profile_dict[\"pp_monthly_p_purchased_sum_df\"],plu_profile_dict[\"pp_monthly_p_purchased_sum_agg_df\"], [\"pluno\"], pp_monthly_p_purchased_sum_new_names, \"pp_p_purchased_sum\")\n",
    "plu_profile_dict[\"pp_bias_ratio_p_purchased_day_ucounts_df\"] = getDeviation(plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_df\"],plu_profile_dict[\"pp_monthly_p_purchased_day_ucounts_agg_df\"], [\"pluno\"], pp_monthly_p_purchased_day_ucounts_new_names, \"pp_p_purchased_day_ucounts\")\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "plu_profile_dict[\"pp_bias_ratio_p_has_u_ucounts_df\"] = getDeviation(plu_profile_dict[\"pp_monthly_p_has_u_ucounts_df\"],plu_profile_dict[\"pp_monthly_p_has_u_ucounts_agg_df\"], [\"pluno\"], pp_monthly_p_has_u_ucounts_new_names, \"pp_p_has_u_ucounts\")\n",
    "\n",
    "\n",
    "pp_ohter_list = [\"pp_p_l_w_purchased_counts_df\", \"pp_p_l_w_purchased_sum_df\", \"pp_p_l_w_purchased_day_ucounts_df\",\n",
    "                \"pp_p_l_w_has_u_ucounts_df\", \"pp_p_l_m_purchased_counts_df\", \"pp_p_l_m_purchased_sum_df\",\n",
    "                \"pp_p_l_m_purchased_day_ucounts_df\", \"pp_p_l_m_has_u_ucounts_df\"]\n",
    "plu_profile_df = commonMergeDataFrame(plu_profile_dict, pp_ohter_list)\n",
    "assert isDifferent(feature_extract_df, [\"pluno\"], plu_profile_df)\n",
    "plu_profile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bnd profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 1)\n",
      "(723, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bndno</th>\n",
       "      <th>bp_b_purchased_counts</th>\n",
       "      <th>bp_b_purchased_sum</th>\n",
       "      <th>bp_b_purchased_day_ucounts</th>\n",
       "      <th>bp_first_b_purchased_counts</th>\n",
       "      <th>bp_second_b_purchased_counts</th>\n",
       "      <th>bp_fourth_b_purchased_counts</th>\n",
       "      <th>bp_fifth_b_purchased_counts</th>\n",
       "      <th>bp_trend_b_purchased_counts_df</th>\n",
       "      <th>bp_first_b_purchased_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>bp_b_purchased_counts_bias_divide_mean</th>\n",
       "      <th>bp_b_purchased_sum__bias</th>\n",
       "      <th>bp_b_purchased_sum__bias_divide_std</th>\n",
       "      <th>bp_b_purchased_sum__bias_divide_mean</th>\n",
       "      <th>bp_b_purchased_day_ucounts_bias</th>\n",
       "      <th>bp_b_purchased_day_ucounts_bias_divide_std</th>\n",
       "      <th>bp_b_purchased_day_ucounts_bias_divide_mean</th>\n",
       "      <th>bp_b_has_u_ucounts_bias</th>\n",
       "      <th>bp_b_has_u_ucounts_bias_divide_std</th>\n",
       "      <th>bp_b_has_u_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6732</td>\n",
       "      <td>71920.800000</td>\n",
       "      <td>122</td>\n",
       "      <td>1751.000000</td>\n",
       "      <td>1790.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>1631.000000</td>\n",
       "      <td>-59.000000</td>\n",
       "      <td>18105.610000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040776</td>\n",
       "      <td>1513.093333</td>\n",
       "      <td>0.839296</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>-0.529813</td>\n",
       "      <td>-0.009535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>3.572634</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10005.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007.000000</td>\n",
       "      <td>41</td>\n",
       "      <td>139.300000</td>\n",
       "      <td>28</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-6.966667</td>\n",
       "      <td>-1.989394</td>\n",
       "      <td>-0.190520</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>-4.618802</td>\n",
       "      <td>-0.347826</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>-1.154701</td>\n",
       "      <td>-0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10012.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-58.000000</td>\n",
       "      <td>-0.484885</td>\n",
       "      <td>-0.604167</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bndno  bp_b_purchased_counts  bp_b_purchased_sum  \\\n",
       "0    -1.000000                   6732        71920.800000   \n",
       "1 10003.000000                      3           20.500000   \n",
       "2 10005.000000                      1           11.000000   \n",
       "3 10007.000000                     41          139.300000   \n",
       "4 10012.000000                      6          326.000000   \n",
       "\n",
       "   bp_b_purchased_day_ucounts  bp_first_b_purchased_counts  \\\n",
       "0                         122                  1751.000000   \n",
       "1                           3                     0.000000   \n",
       "2                           1                     0.000000   \n",
       "3                          28                    14.000000   \n",
       "4                           3                     1.000000   \n",
       "\n",
       "   bp_second_b_purchased_counts  bp_fourth_b_purchased_counts  \\\n",
       "0                   1790.000000                   1560.000000   \n",
       "1                      1.000000                      1.000000   \n",
       "2                      0.000000                      1.000000   \n",
       "3                     10.000000                      8.000000   \n",
       "4                      4.000000                      0.000000   \n",
       "\n",
       "   bp_fifth_b_purchased_counts  bp_trend_b_purchased_counts_df  \\\n",
       "0                  1631.000000                      -59.000000   \n",
       "1                     1.000000                        0.300000   \n",
       "2                     0.000000                        0.100000   \n",
       "3                     9.000000                       -1.700000   \n",
       "4                     1.000000                       -0.400000   \n",
       "\n",
       "   bp_first_b_purchased_sum                 ...                   \\\n",
       "0              18105.610000                 ...                    \n",
       "1                  0.000000                 ...                    \n",
       "2                  0.000000                 ...                    \n",
       "3                 40.600000                 ...                    \n",
       "4                 58.000000                 ...                    \n",
       "\n",
       "   bp_b_purchased_counts_bias_divide_mean  bp_b_purchased_sum__bias  \\\n",
       "0                               -0.040776               1513.093333   \n",
       "1                                0.500000                  9.166667   \n",
       "2                               -1.000000                 -3.666667   \n",
       "3                               -0.156250                 -6.966667   \n",
       "4                               -0.400000                -58.000000   \n",
       "\n",
       "   bp_b_purchased_sum__bias_divide_std  bp_b_purchased_sum__bias_divide_mean  \\\n",
       "0                             0.839296                              0.085962   \n",
       "1                             3.572634                              3.235294   \n",
       "2                            -0.577350                             -1.000000   \n",
       "3                            -1.989394                             -0.190520   \n",
       "4                            -0.484885                             -0.604167   \n",
       "\n",
       "   bp_b_purchased_day_ucounts_bias  \\\n",
       "0                         0.666667   \n",
       "1                         0.333333   \n",
       "2                        -0.333333   \n",
       "3                        -2.666667   \n",
       "4                         0.333333   \n",
       "\n",
       "   bp_b_purchased_day_ucounts_bias_divide_std  \\\n",
       "0                                    1.154701   \n",
       "1                                    0.577350   \n",
       "2                                   -0.577350   \n",
       "3                                   -4.618802   \n",
       "4                                    0.577350   \n",
       "\n",
       "   bp_b_purchased_day_ucounts_bias_divide_mean  bp_b_has_u_ucounts_bias  \\\n",
       "0                                     0.021978                -2.666667   \n",
       "1                                     0.500000                 0.333333   \n",
       "2                                    -1.000000                -0.333333   \n",
       "3                                    -0.347826                -1.333333   \n",
       "4                                     0.500000                 0.333333   \n",
       "\n",
       "   bp_b_has_u_ucounts_bias_divide_std  bp_b_has_u_ucounts_bias_divide_mean  \n",
       "0                           -0.529813                            -0.009535  \n",
       "1                            0.577350                             0.500000  \n",
       "2                           -0.577350                            -1.000000  \n",
       "3                           -1.154701                            -0.160000  \n",
       "4                            0.577350                             0.500000  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 812个品牌\n",
    "bnd_profile_dict = {}\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. bnd被购买总次数\n",
    "# 2. bnd被购买总金额\n",
    "# 3. bnd被购买总天数\n",
    "bnd_profile_dict[\"bp_b_purchased_counts_df\"] = getTotalCounts(feature_extract_df, [\"bndno\"], \"id\", \"bp_b_purchased_counts\", False)\n",
    "bnd_profile_dict[\"bp_b_purchased_sum_df\"] = getTotalSum(feature_extract_df, [\"bndno\"], \"amt\", \"bp_b_purchased_sum\")\n",
    "bnd_profile_dict[\"bp_b_purchased_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"bndno\"], \"just_date\", \"bp_b_purchased_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. bnd每月被购买次数\n",
    "# 2. bnd每月被购买金额\n",
    "# 3. bnd每月被购买天数\n",
    "bp_monthly_b_purchased_counts_new_names = getMonthlyNames(\"bp\", \"b_purchased_counts\")\n",
    "bp_monthly_b_purchased_sum_new_names = getMonthlyNames(\"bp\", \"b_purchased_sum\")\n",
    "bp_monthly_b_purchased_day_ucounts_new_names = getMonthlyNames(\"bp\", \"b_purchased_day_ucounts\")\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"bndno\"], \"id\", bp_monthly_b_purchased_counts_new_names, False)\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_sum_df\"] = getMonthlySum(feature_extract_df, [\"bndno\"], \"amt\", bp_monthly_b_purchased_sum_new_names)\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"bndno\"], \"just_date\", bp_monthly_b_purchased_day_ucounts_new_names, True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# whold period\n",
    "bnd_profile_dict[\"bp_b_has_p_ucounts_df\"] =  getTotalCounts(feature_extract_df, [\"bndno\"], \"pluno\", \"bp_b_has_p_ucounts\", True)\n",
    "#\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# monthly\n",
    "# 1. 包含的unique的I的数量\n",
    "# 不知道有无意义\n",
    "bp_monthly_b_has_p_counts_new_names = getMonthlyNames(\"bp\", \"b_has_p_ucounts\")\n",
    "bnd_profile_dict[\"bp_monthly_b_has_p_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"bndno\"], \"pluno\", bp_monthly_b_has_p_counts_new_names, True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "# whold period\n",
    "# 1. 买过该品牌或品类或商品的不同的买家的人数\n",
    "bnd_profile_dict[\"bp_b_has_u_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"bndno\"], \"vipno\", \"bp_b_has_u_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "# monthly\n",
    "# 1. 每月买过该品牌或品类或商品的不同的买家的人数\n",
    "bp_monthly_b_has_u_ucounts_new_names = getMonthlyNames(\"bp\", \"b_has_u_ucounts\")\n",
    "bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"bndno\"], \"vipno\", bp_monthly_b_has_u_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_counts_agg_df\"] = getMonthAgg(bnd_profile_dict[\"bp_monthly_b_purchased_counts_df\"], [\"bndno\"], 1, \"bp_monthly_b_purchased_counts\")\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_sum_agg_df\"] = getMonthAgg(bnd_profile_dict[\"bp_monthly_b_purchased_sum_df\"], [\"bndno\"], 1, \"bp_monthly_b_purchased_sum\")\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_agg_df\"] = getMonthAgg(bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_df\"], [\"bndno\"], 1, \"bp_monthly_b_purchased_day_ucounts\")\n",
    "# 2. agg: TYPE.1 count/ratio - product diversity\n",
    "bnd_profile_dict[\"bp_monthly_b_has_p_ucounts_agg_df\"] = getMonthAgg(bnd_profile_dict[\"bp_monthly_b_has_p_ucounts_df\"], [\"bndno\"], 1, \"bp_monthly_b_has_p_ucounts\")\n",
    "# 3. agg: TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_agg_df\"] = getMonthAgg(bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_df\"], [\"bndno\"], 1, \"bp_monthly_b_has_u_ucounts\")\n",
    "\n",
    "\n",
    "# TYPE.2 AGG feature - user AGG\n",
    "# agg_type: 0 - count 1 - nunique 2 - sum\n",
    "bnd_profile_dict[\"bp_bnd_user_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"bndno\", \"vipno\"], \"bndno\", \"id\", 2, \"bp_bnd_user_agg_counts\", 0)\n",
    "bnd_profile_dict[\"bp_bnd_user_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"bndno\", \"vipno\"], \"bndno\", \"amt\", 2, \"bp_bnd_user_agg_sum\", 2)\n",
    "bnd_profile_dict[\"bp_bnd_user_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"bndno\", \"vipno\"], \"bndno\", \"just_date\", 2, \"bp_bnd_user_agg_day_ucounts\", 1)\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week\n",
    "# TYPE.1 count/ratio - count\n",
    "bnd_profile_dict[\"bp_b_l_w_purchased_counts_df\"] = getTotalCounts(last_week_df, [\"bndno\"], \"id\", \"bp_b_l_w_purchased_counts\", False)\n",
    "bnd_profile_dict[\"bp_b_l_w_purchased_sum_df\"] = getTotalSum(last_week_df, [\"bndno\"], \"amt\", \"bp_b_l_w_purchased_sum\")\n",
    "bnd_profile_dict[\"bp_b_l_w_purchased_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"bndno\"], \"just_date\", \"bp_b_l_w_purchased_day_ucounts\", True)\n",
    "# last week\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "bnd_profile_dict[\"bp_b_l_w_has_p_ucounts_df\"] =  getTotalCounts(last_week_df, [\"bndno\"], \"pluno\", \"bp_b_l_w_has_p_ucounts\", True)\n",
    "# last week\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "bnd_profile_dict[\"bp_b_l_w_has_u_ucounts_df\"] = getTotalCounts(last_week_df, [\"bndno\"], \"vipno\", \"bp_b_l_w_has_u_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "bnd_profile_dict[\"bp_b_l_m_purchased_counts_df\"] = getTotalCounts(last_month_df, [\"bndno\"], \"id\", \"bp_b_l_m_purchased_counts\", False)\n",
    "bnd_profile_dict[\"bp_b_l_m_purchased_sum_df\"] = getTotalSum(last_month_df, [\"bndno\"], \"amt\", \"bp_b_l_m_purchased_sum\")\n",
    "bnd_profile_dict[\"bp_b_l_m_purchased_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"bndno\"], \"just_date\", \"bp_b_l_m_purchased_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "bnd_profile_dict[\"bp_b_l_m_has_p_ucounts_df\"] =  getTotalCounts(last_month_df, [\"bndno\"], \"pluno\", \"bp_b_l_m_has_p_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "bnd_profile_dict[\"bp_b_l_m_has_u_ucounts_df\"] = getTotalCounts(last_month_df, [\"bndno\"], \"vipno\", \"bp_b_l_m_has_u_ucounts\", True)\n",
    "\n",
    "# \n",
    "# TYPE.4 complex feature - repeat feature\n",
    "# 统计repeat buyer的count/ratio\n",
    "# 1. count:至少两天购买同一I或B或C的人数\n",
    "# 2. ratio:count / 购买该I或B或C的总人数\n",
    "bnd_profile_dict[\"bp_bnd_repeat_buyer_df\"] = getRepeatFeature(feature_extract_df, [\"bndno\", \"vipno\"], \"bp_bnd_repeat_buyer\")\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_counts_df\"][\"bp_trend_b_purchased_counts_df\"] = bnd_profile_dict[\"bp_monthly_b_purchased_counts_df\"].apply(getTrend, axis=1)\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_sum_df\"][\"bp_trend_b_purchased_sum_df\"] = bnd_profile_dict[\"bp_monthly_b_purchased_sum_df\"].apply(getTrend, axis=1)\n",
    "bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_df\"][\"bp_trend_b_purchased_day_ucounts_df\"] = bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "bnd_profile_dict[\"bp_monthly_b_has_p_ucounts_df\"][\"bp_trend_b_has_p_ucounts_df\"] = bnd_profile_dict[\"bp_monthly_b_has_p_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_df\"][\"bp_trend_b_has_u_ucounts_df\"] = bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "bnd_profile_dict[\"bp_bias_ratio_b_purchased_counts_df\"] = getDeviation(bnd_profile_dict[\"bp_monthly_b_purchased_counts_df\"], bnd_profile_dict[\"bp_monthly_b_purchased_counts_agg_df\"], [\"bndno\"], bp_monthly_b_purchased_counts_new_names, \"bp_b_purchased_counts\")\n",
    "bnd_profile_dict[\"bp_bias_ratio_b_purchased_sum_df\"] = getDeviation(bnd_profile_dict[\"bp_monthly_b_purchased_sum_df\"], bnd_profile_dict[\"bp_monthly_b_purchased_sum_agg_df\"], [\"bndno\"], bp_monthly_b_purchased_sum_new_names, \"bp_b_purchased_sum_\")\n",
    "bnd_profile_dict[\"bp_bias_ratio_b_purchased_day_ucounts_df\"] = getDeviation(bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_df\"],bnd_profile_dict[\"bp_monthly_b_purchased_day_ucounts_agg_df\"], [\"bndno\"], bp_monthly_b_purchased_day_ucounts_new_names, \"bp_b_purchased_day_ucounts\")\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "bnd_profile_dict[\"bp_bias_ratio_b_has_u_ucounts_df\"] = getDeviation(bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_df\"],bnd_profile_dict[\"bp_monthly_b_has_u_ucounts_agg_df\"], [\"bndno\"], bp_monthly_b_has_u_ucounts_new_names, \"bp_b_has_u_ucounts\")\n",
    "\n",
    "\n",
    "bp_other_list = [\"bp_b_l_w_purchased_counts_df\", \"bp_b_l_w_purchased_sum_df\", \"bp_b_l_w_purchased_day_ucounts_df\",\n",
    "                \"bp_b_l_w_has_p_ucounts_df\", \"bp_b_l_w_has_u_ucounts_df\", \"bp_b_l_m_purchased_counts_df\",\n",
    "                \"bp_b_l_m_purchased_sum_df\", \"bp_b_l_m_purchased_day_ucounts_df\", \"bp_b_l_m_has_p_ucounts_df\",\n",
    "                \"bp_b_l_m_has_u_ucounts_df\"]\n",
    "bnd_profile_df = commonMergeDataFrame(bnd_profile_dict, bp_other_list)\n",
    "assert isDifferent(feature_extract_df, [\"bndno\"], bnd_profile_df)\n",
    "bnd_profile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dpt profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(838, 1)\n",
      "(838, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dptno</th>\n",
       "      <th>dp_d_purchased_counts</th>\n",
       "      <th>dp_d_purchased_sum</th>\n",
       "      <th>dp_d_purchased_day_ucounts</th>\n",
       "      <th>dp_first_d_purchased_counts</th>\n",
       "      <th>dp_second_d_purchased_counts</th>\n",
       "      <th>dp_fourth_d_purchased_counts</th>\n",
       "      <th>dp_fifth_d_purchased_counts</th>\n",
       "      <th>dp_trend_d_purchased_counts_df</th>\n",
       "      <th>dp_first_d_purchased_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_d_purchased_counts_bias_divide_mean</th>\n",
       "      <th>dp_d_purchased_sum__bias</th>\n",
       "      <th>dp_d_purchased_sum__bias_divide_std</th>\n",
       "      <th>dp_d_purchased_sum__bias_divide_mean</th>\n",
       "      <th>dp_d_purchased_day_ucounts_bias</th>\n",
       "      <th>dp_d_purchased_day_ucounts_bias_divide_std</th>\n",
       "      <th>dp_d_purchased_day_ucounts_bias_divide_mean</th>\n",
       "      <th>dp_d_has_u_ucounts_bias</th>\n",
       "      <th>dp_d_has_u_ucounts_bias_divide_std</th>\n",
       "      <th>dp_d_has_u_ucounts_bias_divide_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>90</td>\n",
       "      <td>344.700000</td>\n",
       "      <td>59</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>0.764626</td>\n",
       "      <td>0.072863</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>16</td>\n",
       "      <td>50.300000</td>\n",
       "      <td>15</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>61</td>\n",
       "      <td>389.300000</td>\n",
       "      <td>41</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>107.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411765</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>0.579975</td>\n",
       "      <td>0.073596</td>\n",
       "      <td>-4.333333</td>\n",
       "      <td>-7.505553</td>\n",
       "      <td>-0.382353</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>17</td>\n",
       "      <td>90.400000</td>\n",
       "      <td>16</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.900000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-30.133333</td>\n",
       "      <td>-3.957610</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.333333</td>\n",
       "      <td>-9.237604</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>-8.082904</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10100</td>\n",
       "      <td>16</td>\n",
       "      <td>191.400000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.944160</td>\n",
       "      <td>1.023622</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.927173</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dptno  dp_d_purchased_counts  dp_d_purchased_sum  \\\n",
       "0  10000                     90          344.700000   \n",
       "1  10001                     16           50.300000   \n",
       "2  10002                     61          389.300000   \n",
       "3  10008                     17           90.400000   \n",
       "4  10100                     16          191.400000   \n",
       "\n",
       "   dp_d_purchased_day_ucounts  dp_first_d_purchased_counts  \\\n",
       "0                          59                    25.000000   \n",
       "1                          15                     2.000000   \n",
       "2                          41                    15.000000   \n",
       "3                          16                     6.000000   \n",
       "4                          13                     0.000000   \n",
       "\n",
       "   dp_second_d_purchased_counts  dp_fourth_d_purchased_counts  \\\n",
       "0                     18.000000                     24.000000   \n",
       "1                      5.000000                      5.000000   \n",
       "2                     17.000000                     19.000000   \n",
       "3                      6.000000                      5.000000   \n",
       "4                      6.000000                      5.000000   \n",
       "\n",
       "   dp_fifth_d_purchased_counts  dp_trend_d_purchased_counts_df  \\\n",
       "0                    23.000000                        0.000000   \n",
       "1                     4.000000                        0.600000   \n",
       "2                    10.000000                       -1.300000   \n",
       "3                     0.000000                       -1.900000   \n",
       "4                     5.000000                        1.400000   \n",
       "\n",
       "   dp_first_d_purchased_sum                 ...                   \\\n",
       "0                 80.800000                 ...                    \n",
       "1                  8.900000                 ...                    \n",
       "2                107.200000                 ...                    \n",
       "3                 38.000000                 ...                    \n",
       "4                  0.000000                 ...                    \n",
       "\n",
       "   dp_d_purchased_counts_bias_divide_mean  dp_d_purchased_sum__bias  \\\n",
       "0                                0.029851                  6.166667   \n",
       "1                                0.000000                  0.033333   \n",
       "2                               -0.411765                  7.033333   \n",
       "3                               -1.000000                -30.133333   \n",
       "4                                0.363636                 39.000000   \n",
       "\n",
       "   dp_d_purchased_sum__bias_divide_std  dp_d_purchased_sum__bias_divide_mean  \\\n",
       "0                             0.764626                              0.072863   \n",
       "1                             0.010099                              0.002653   \n",
       "2                             0.579975                              0.073596   \n",
       "3                            -3.957610                             -1.000000   \n",
       "4                             0.944160                              1.023622   \n",
       "\n",
       "   dp_d_purchased_day_ucounts_bias  \\\n",
       "0                         1.666667   \n",
       "1                         0.333333   \n",
       "2                        -4.333333   \n",
       "3                        -5.333333   \n",
       "4                         2.333333   \n",
       "\n",
       "   dp_d_purchased_day_ucounts_bias_divide_std  \\\n",
       "0                                    2.886751   \n",
       "1                                    0.218218   \n",
       "2                                   -7.505553   \n",
       "3                                   -9.237604   \n",
       "4                                    0.927173   \n",
       "\n",
       "   dp_d_purchased_day_ucounts_bias_divide_mean  dp_d_has_u_ucounts_bias  \\\n",
       "0                                     0.116279                 1.666667   \n",
       "1                                     0.090909                 0.333333   \n",
       "2                                    -0.382353                -3.000000   \n",
       "3                                    -1.000000                -4.666667   \n",
       "4                                     0.875000                 2.000000   \n",
       "\n",
       "   dp_d_has_u_ucounts_bias_divide_std  dp_d_has_u_ucounts_bias_divide_mean  \n",
       "0                            2.886751                             0.102041  \n",
       "1                            0.288675                             0.125000  \n",
       "2                           -3.000000                            -0.250000  \n",
       "3                           -8.082904                            -1.000000  \n",
       "4                            0.755929                             0.666667  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 936个类型\n",
    "dpt_profile_dict = {}\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# whold period\n",
    "# 1. dpt被购买总次数\n",
    "# 2. dpt被购买总金额\n",
    "# 3. dpt被购买总天数\n",
    "dpt_profile_dict[\"dp_d_purchased_counts_df\"] = getTotalCounts(feature_extract_df, [\"dptno\"], \"id\", \"dp_d_purchased_counts\", False)\n",
    "dpt_profile_dict[\"dp_d_purchased_sum_df\"] = getTotalSum(feature_extract_df, [\"dptno\"], \"amt\", \"dp_d_purchased_sum\")\n",
    "dpt_profile_dict[\"dp_d_purchased_day_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"dptno\"], \"just_date\", \"dp_d_purchased_day_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - count\n",
    "# monthly\n",
    "# 1. dpt每月被购买次数\n",
    "# 2. dpt每月被购买金额\n",
    "# 3. dpt每月被购买天数\n",
    "dp_monthly_d_purchased_counts_new_names = getMonthlyNames(\"dp\", \"d_purchased_counts\")\n",
    "dp_monthly_d_purchased_sum_new_names = getMonthlyNames(\"dp\", \"d_purchased_sum\")\n",
    "dp_monthly_d_purchased_day_ucounts_new_names = getMonthlyNames(\"dp\", \"d_purchased_day_ucounts\")\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_counts_df\"] = getMonthlyCounts(feature_extract_df, [\"dptno\"], \"id\", dp_monthly_d_purchased_counts_new_names, False)\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_sum_df\"] = getMonthlySum(feature_extract_df, [\"dptno\"], \"amt\", dp_monthly_d_purchased_sum_new_names)\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"dptno\"], \"just_date\", dp_monthly_d_purchased_day_ucounts_new_names, True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# whole period\n",
    "# 1. 包含的unique的I的数量\n",
    "dpt_profile_dict[\"dp_d_has_p_ucounts_df\"] =  getTotalCounts(feature_extract_df, [\"dptno\"], \"pluno\", \"dp_d_has_p_ucounts\", True)\n",
    "#\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "# monthly\n",
    "# 1. 包含的unique的I的数量\n",
    "# 不知道有无意义\n",
    "dp_monthly_d_has_p_ucounts_new_names = getMonthlyNames(\"dp\", \"d_has_p_ucounts\") \n",
    "dpt_profile_dict[\"dp_monthly_d_has_p_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"dptno\"], \"pluno\", dp_monthly_d_has_p_ucounts_new_names, True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品类名声\n",
    "# whold period\n",
    "# 1. 买过该品牌或品类或商品的不同的买家的人数\n",
    "dpt_profile_dict[\"dp_d_has_u_ucounts_df\"] = getTotalCounts(feature_extract_df, [\"dptno\"], \"vipno\", \"dp_d_has_u_ucounts\", True)\n",
    "\n",
    "#\n",
    "# TYPE.1 count/ratio - penetration 衡量品类名声\n",
    "# monthly\n",
    "# 1. 每月买过该品牌或品类或商品的不同的买家的人数\n",
    "dp_monthly_d_has_u_ucounts_new_names = getMonthlyNames(\"dp\", \"d_has_u_ucounts\")\n",
    "dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_df\"] = getMonthlyCounts(feature_extract_df, [\"dptno\"], \"vipno\", dp_monthly_d_has_u_ucounts_new_names, True)\n",
    "\n",
    "# \n",
    "# TYPE.2 AGG feature - month AGG\n",
    "# 针对TYPE.1 中所有的monthly特征，都可以进行此aggregation agg操作包含mean、std、max、median\n",
    "# 1. agg: TYPE.1 count/ratio - count\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_counts_agg_df\"] = getMonthAgg(dpt_profile_dict[\"dp_monthly_d_purchased_counts_df\"], [\"dptno\"], 1, \"dpt_monthly_d_purchased_counts\")\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_sum_agg_df\"] = getMonthAgg(dpt_profile_dict[\"dp_monthly_d_purchased_sum_df\"], [\"dptno\"], 1, \"dpt_monthly_d_purchased_sum\")\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_agg_df\"] = getMonthAgg(dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_df\"], [\"dptno\"], 1, \"dpt_monthly_d_purchased_day_ucounts\")\n",
    "# 2. agg: TYPE.1 count/ratio - product diversity\n",
    "dpt_profile_dict[\"dp_monthly_d_has_p_ucounts_agg_df\"] = getMonthAgg(dpt_profile_dict[\"dp_monthly_d_has_p_ucounts_df\"], [\"dptno\"], 1, \"dp_monthly_d_has_p_ucounts\")\n",
    "# 3. agg: TYPE.1 count/ratio - penetration 衡量品类名声\n",
    "dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_agg_df\"] = getMonthAgg(dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_df\"], [\"dptno\"], 1, \"dp_monthly_d_has_u_ucounts\")\n",
    "\n",
    "# TYPE.2 AGG feature - user AGG\n",
    "# agg_type: 0 - count 1 - nunique 2 - sum\n",
    "dpt_profile_dict[\"dp_dp_user_agg_counts_df\"] = getUIBCAgg(feature_extract_df, [\"dptno\", \"vipno\"], \"dptno\", \"id\", 2, \"dp_dpt_user_agg_counts\", 0)\n",
    "dpt_profile_dict[\"dp_dp_user_agg_sum_df\"] = getUIBCAgg(feature_extract_df, [\"dptno\", \"vipno\"], \"dptno\", \"amt\", 2, \"dp_dpt_user_agg_sum\", 2)\n",
    "dpt_profile_dict[\"dp_dp_user_agg_day_ucounts_df\"] = getUIBCAgg(feature_extract_df, [\"dptno\", \"vipno\"], \"dptno\", \"just_date\", 2, \"dp_dpt_user_agg_day_ucounts\", 1)\n",
    "\n",
    "# \n",
    "# TYPE.3 last week / last month feature\n",
    "# 将时间范围缩小，再进行TYPE.1 和TYPE.2 的特征统计，此时没有 monthly特征和monthly agg特征\n",
    "# last week\n",
    "# TYPE.1 count/ratio - count\n",
    "dpt_profile_dict[\"dp_d_l_w_purchased_counts_df\"] = getTotalCounts(last_week_df, [\"dptno\"], \"id\", \"dp_d_l_w_purchased_counts\", False)\n",
    "dpt_profile_dict[\"dp_d_l_w_purchased_sum_df\"] = getTotalSum(last_week_df, [\"dptno\"], \"amt\", \"dp_d_l_w_purchased_sum\")\n",
    "dpt_profile_dict[\"dp_d_l_w_purchased_day_ucounts_df\"] = getTotalCounts(last_week_df, [\"dptno\"], \"just_date\", \"dp_d_l_w_purchased_day_ucounts\", True)\n",
    "# last week\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "dpt_profile_dict[\"dp_d_l_w_has_p_ucounts_df\"] =  getTotalCounts(last_week_df, [\"dptno\"], \"pluno\", \"dp_d_l_w_has_p_ucounts\", True)\n",
    "# last week\n",
    "# TYPE.1 count/ratio - penetration 衡量品类名声\n",
    "dpt_profile_dict[\"dp_d_l_w_has_u_ucounts_df\"] = getTotalCounts(last_week_df, [\"dptno\"], \"vipno\", \"dp_d_l_w_has_u_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - count\n",
    "dpt_profile_dict[\"dp_d_l_m_purchased_counts_df\"] = getTotalCounts(last_month_df, [\"dptno\"], \"id\", \"dp_d_l_m_purchased_counts\", False)\n",
    "dpt_profile_dict[\"dp_d_l_m_purchased_sum_df\"] = getTotalSum(last_month_df, [\"dptno\"], \"amt\", \"dp_d_l_m_purchased_sum\")\n",
    "dpt_profile_dict[\"dp_d_l_m_purchased_day_ucounts_df\"] = getTotalCounts(last_month_df, [\"dptno\"], \"just_date\", \"dp_d_l_m_purchased_day_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "dpt_profile_dict[\"dp_d_l_m_has_p_ucounts_df\"] =  getTotalCounts(last_month_df, [\"dptno\"], \"pluno\", \"dp_d_l_m_has_p_ucounts\", True)\n",
    "# last month\n",
    "# TYPE.1 count/ratio - penetration 衡量品类名声\n",
    "dpt_profile_dict[\"dp_d_l_m_has_u_ucounts_df\"] = getTotalCounts(last_month_df, [\"dptno\"], \"vipno\", \"dp_d_l_m_has_u_ucounts\", True)\n",
    "\n",
    "\n",
    "# \n",
    "# TYPE.4 complex feature - repeat feature\n",
    "# 统计repeat buyer的count/ratio\n",
    "# 1. count:至少两天购买同一I或B或C的人数\n",
    "# 2. ratio:count / 购买该I或B或C的总人数\n",
    "dpt_profile_dict[\"dp_dpt_repeat_buyer_df\"] = getRepeatFeature(feature_extract_df, [\"dptno\", \"vipno\"], \"dp_dpt_repeat_buyer\")\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 1. 基于TYPE.1 中的monthly feature，一个monthly feature计算出 一个trend\n",
    "# TYPE.1 count/ratio - count\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_counts_df\"][\"dp_trend_d_purchased_counts_df\"] = dpt_profile_dict[\"dp_monthly_d_purchased_counts_df\"].apply(getTrend, axis=1)\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_sum_df\"][\"dp_trend_d_purchased_sum_df\"] = dpt_profile_dict[\"dp_monthly_d_purchased_sum_df\"].apply(getTrend, axis=1)\n",
    "dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_df\"][\"dp_trend_d_purchased_day_ucounts_df\"] = dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - product diversity\n",
    "dpt_profile_dict[\"dp_monthly_d_has_p_ucounts_df\"][\"dp_trend_d_has_p_ucounts_df\"] = dpt_profile_dict[\"dp_monthly_d_has_p_ucounts_df\"].apply(getTrend, axis=1)\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_df\"][\"dp_trend_d_has_u_ucounts_df\"] = dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_df\"].apply(getTrend, axis=1)\n",
    "\n",
    "#\n",
    "# TYPE.4 complex feature - trend\n",
    "# 2. 基于TYPE.1 中的monthly feature，算最后一个月与前几个月均 值的偏差，并用均值或者标准差normalize\n",
    "# TYPE.1 count/ratio - count\n",
    "dpt_profile_dict[\"dp_bias_ratio_d_purchased_counts_df\"] = getDeviation(dpt_profile_dict[\"dp_monthly_d_purchased_counts_df\"], dpt_profile_dict[\"dp_monthly_d_purchased_counts_agg_df\"], [\"dptno\"], dp_monthly_d_purchased_counts_new_names, \"dp_d_purchased_counts\")\n",
    "dpt_profile_dict[\"dp_bias_ratio_d_purchased_sum_df\"] = getDeviation(dpt_profile_dict[\"dp_monthly_d_purchased_sum_df\"], dpt_profile_dict[\"dp_monthly_d_purchased_sum_agg_df\"], [\"dptno\"], dp_monthly_d_purchased_sum_new_names, \"dp_d_purchased_sum_\")\n",
    "dpt_profile_dict[\"dp_bias_ratio_d_purchased_day_ucounts_df\"] = getDeviation(dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_df\"],dpt_profile_dict[\"dp_monthly_d_purchased_day_ucounts_agg_df\"], [\"dptno\"], dp_monthly_d_purchased_day_ucounts_new_names, \"dp_d_purchased_day_ucounts\")\n",
    "# TYPE.1 count/ratio - penetration 衡量品牌名声\n",
    "dpt_profile_dict[\"dp_bias_ratio_d_has_u_ucounts_df\"] = getDeviation(dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_df\"],dpt_profile_dict[\"dp_monthly_d_has_u_ucounts_agg_df\"], [\"dptno\"], dp_monthly_d_has_u_ucounts_new_names, \"dp_d_has_u_ucounts\")\n",
    "\n",
    "dpt_other_list = [\"dp_d_l_w_purchased_counts_df\", \"dp_d_l_w_purchased_sum_df\", \"dp_d_l_w_purchased_day_ucounts_df\",\n",
    "                 \"dp_d_l_w_has_p_ucounts_df\", \"dp_d_l_w_has_u_ucounts_df\", \"dp_d_l_m_purchased_counts_df\",\n",
    "                 \"dp_d_l_m_purchased_sum_df\", \"dp_d_l_m_purchased_day_ucounts_df\", \"dp_d_l_m_has_p_ucounts_df\", \n",
    "                 \"dp_d_l_m_has_u_ucounts_df\"]\n",
    "dpt_profile_df = commonMergeDataFrame(dpt_profile_dict, dpt_other_list)\n",
    "assert isDifferent(feature_extract_df, [\"dptno\"], dpt_profile_df)\n",
    "dpt_profile_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1789, 2)\n",
      "(1789, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bndno</th>\n",
       "      <th>dptno</th>\n",
       "      <th>bcp_c_in_b_count_ratio</th>\n",
       "      <th>bcp_c_in_b_user_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10110</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10113</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10114</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10116</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10119</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.004566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bndno  dptno  bcp_c_in_b_count_ratio  bcp_c_in_b_user_ratio\n",
       "0 -1.000000  10110                0.000743               0.009132\n",
       "1 -1.000000  10113                0.000149               0.002283\n",
       "2 -1.000000  10114                0.000446               0.006849\n",
       "3 -1.000000  10116                0.000446               0.006849\n",
       "4 -1.000000  10119                0.000446               0.004566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMarketShare(input_df, group_by_1, group_by_2, use_col, new_col_name, isUnique):\n",
    "    res_df = None\n",
    "    i_df = input_df.copy()\n",
    "    temp1 = getTotalCounts(i_df, group_by_1, use_col, \"_total_count\", isUnique)\n",
    "    temp2 = getTotalCounts(i_df, group_by_2, use_col, \"_part_count\", isUnique)\n",
    "    temp2 = temp2.merge(temp1)\n",
    "    temp2[new_col_name] = temp2[\"_part_count\"] / temp2[\"_total_count\"]\n",
    "    res_df = temp2[group_by_2 + [new_col_name]]\n",
    "    return res_df\n",
    "bd_profile_dict = {}\n",
    "\n",
    "bd_profile_dict[\"bcp_c_in_b_count_ratio_df\"] = getMarketShare(feature_extract_df, [\"bndno\"], [\"bndno\", \"dptno\"], \"id\", \"bcp_c_in_b_count_ratio\", False)\n",
    "bd_profile_dict[\"bcp_c_in_b_user_ratio_df\"] = getMarketShare(feature_extract_df, [\"bndno\"], [\"bndno\", \"dptno\"], \"vipno\", \"bcp_c_in_b_user_ratio\", True)\n",
    "\n",
    "bd_profile_df = commonMergeDataFrame(bd_profile_dict)\n",
    "assert isDifferent(feature_extract_df, [\"bndno\", \"dptno\"], bd_profile_df)\n",
    "bd_profile_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1789, 2)\n",
      "(1789, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dptno</th>\n",
       "      <th>bndno</th>\n",
       "      <th>cbp_b_in_c_count_ratio</th>\n",
       "      <th>cbp_b_in_c_user_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>10007.000000</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>10062.000000</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>10068.000000</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>10064.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002</td>\n",
       "      <td>10062.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dptno        bndno  cbp_b_in_c_count_ratio  cbp_b_in_c_user_ratio\n",
       "0  10000 10007.000000                0.377778               0.400000\n",
       "1  10000 10062.000000                0.477778               0.545455\n",
       "2  10000 10068.000000                0.144444               0.109091\n",
       "3  10001 10064.000000                1.000000               1.000000\n",
       "4  10002 10062.000000                0.016393               0.027778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_profile_dict = {}\n",
    "db_profile_dict[\"cbp_b_in_c_count_ratio_df\"] = getMarketShare(feature_extract_df, [\"dptno\"], [\"dptno\", \"bndno\"], \"id\", \"cbp_b_in_c_count_ratio\", False)\n",
    "db_profile_dict[\"cbp_b_in_c_user_ratio_df\"] = getMarketShare(feature_extract_df, [\"dptno\"], [\"dptno\", \"bndno\"], \"vipno\", \"cbp_b_in_c_user_ratio\", True)\n",
    "\n",
    "db_profile_df = commonMergeDataFrame(db_profile_dict)\n",
    "assert isDifferent(feature_extract_df, [\"dptno\", \"bndno\"], db_profile_df)\n",
    "db_profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_b_profile_df2 = feature_extract_df.groupby([\"vipno\", \"bndno\"])[\"id\"].count().reset_index().rename(columns={\"id\":\"count\"})\n",
    "u_d_profile_df2 = feature_extract_df.groupby([\"vipno\", \"dptno\"])[\"id\"].count().reset_index().rename(columns={\"id\":\"count\"})\n",
    "\n",
    "ubd_df = feature_extract_df.groupby([\"vipno\", \"bndno\",\"dptno\"])[\"id\"].count().reset_index().rename(columns={\"id\":\"count\"})\n",
    "bd_df = bd_profile_df.copy()\n",
    "\n",
    "udb_df = feature_extract_df.groupby([\"vipno\", \"dptno\", \"bndno\"])[\"id\"].count().reset_index().rename(columns={\"id\":\"count\"})\n",
    "db_df = db_profile_df.copy()\n",
    "\n",
    "def generate(x, i_ubd_or_udb_df, i_bd_or_db_df, condition_col, ratio_col, agg_type):\n",
    "    temp_df = i_ubd_or_udb_df.loc[(i_ubd_or_udb_df[\"vipno\"] == x[\"vipno\"]) & (i_ubd_or_udb_df[condition_col] == x[condition_col])]\n",
    "    temp_df = temp_df.merge(i_bd_or_db_df)\n",
    "    temp_df[\"count*count_ratio\"] = temp_df[\"count\"] * temp_df[ratio_col]\n",
    "    if agg_type == 0:\n",
    "        return temp_df[\"count*count_ratio\"].max()\n",
    "    elif agg_type == 1:\n",
    "        return temp_df[\"count*count_ratio\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vipno</th>\n",
       "      <th>bndno</th>\n",
       "      <th>count</th>\n",
       "      <th>ubp_similarity_max_1</th>\n",
       "      <th>ubp_similarity_max_2</th>\n",
       "      <th>ubp_similarity_mean_1</th>\n",
       "      <th>ubp_similarity_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781924</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.081431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>781924</td>\n",
       "      <td>10106.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>781924</td>\n",
       "      <td>10706.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781924</td>\n",
       "      <td>11129.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>781924</td>\n",
       "      <td>11149.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vipno        bndno  count  ubp_similarity_max_1  ubp_similarity_max_2  \\\n",
       "0  781924    -1.000000      5              0.020053              0.123288   \n",
       "1  781924 10106.000000      1              0.361702              0.354839   \n",
       "2  781924 10706.000000      1              0.015038              0.046512   \n",
       "3  781924 11129.000000      1              0.482759              0.482759   \n",
       "4  781924 11149.000000      1              0.250000              0.333333   \n",
       "\n",
       "   ubp_similarity_mean_1  ubp_similarity_mean_2  \n",
       "0               0.010596               0.081431  \n",
       "1               0.361702               0.354839  \n",
       "2               0.015038               0.046512  \n",
       "3               0.482759               0.482759  \n",
       "4               0.250000               0.333333  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_b_profile_df2[\"ubp_similarity_max_1\"] = u_b_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = ubd_df, i_bd_or_db_df = bd_df, condition_col = \"bndno\", ratio_col = \"bcp_c_in_b_count_ratio\", agg_type=0)\n",
    "u_b_profile_df2[\"ubp_similarity_max_2\"] = u_b_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = ubd_df, i_bd_or_db_df = bd_df, condition_col = \"bndno\", ratio_col = \"bcp_c_in_b_user_ratio\", agg_type=0)\n",
    "u_b_profile_df2[\"ubp_similarity_mean_1\"] = u_b_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = ubd_df, i_bd_or_db_df = bd_df, condition_col = \"bndno\", ratio_col = \"bcp_c_in_b_count_ratio\", agg_type=1)\n",
    "u_b_profile_df2[\"ubp_similarity_mean_2\"] = u_b_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = ubd_df, i_bd_or_db_df = bd_df, condition_col = \"bndno\", ratio_col = \"bcp_c_in_b_user_ratio\", agg_type=1)\n",
    "\n",
    "u_b_profile_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vipno</th>\n",
       "      <th>dptno</th>\n",
       "      <th>count</th>\n",
       "      <th>udp_similarity_max_1</th>\n",
       "      <th>udp_similarity_max_2</th>\n",
       "      <th>udp_similarity_mean_1</th>\n",
       "      <th>udp_similarity_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>781924</td>\n",
       "      <td>10113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>781924</td>\n",
       "      <td>10130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>781924</td>\n",
       "      <td>11302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781924</td>\n",
       "      <td>11531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>781924</td>\n",
       "      <td>11532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    vipno  dptno  count  udp_similarity_max_1  udp_similarity_max_2  \\\n",
       "0  781924  10113      1              0.200000              0.222222   \n",
       "1  781924  10130      1              0.459459              0.478261   \n",
       "2  781924  11302      1              0.153846              0.166667   \n",
       "3  781924  11531      1              0.045455              0.047619   \n",
       "4  781924  11532      2              0.285714              0.388889   \n",
       "\n",
       "   udp_similarity_mean_1  udp_similarity_mean_2  \n",
       "0               0.200000               0.222222  \n",
       "1               0.459459               0.478261  \n",
       "2               0.153846               0.166667  \n",
       "3               0.045455               0.047619  \n",
       "4               0.265306               0.277778  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_d_profile_df2[\"udp_similarity_max_1\"] = u_d_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = udb_df, i_bd_or_db_df = db_df, condition_col = \"dptno\", ratio_col = \"cbp_b_in_c_count_ratio\", agg_type=0)\n",
    "u_d_profile_df2[\"udp_similarity_max_2\"] = u_d_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = udb_df, i_bd_or_db_df = db_df, condition_col = \"dptno\", ratio_col = \"cbp_b_in_c_user_ratio\", agg_type=0)\n",
    "u_d_profile_df2[\"udp_similarity_mean_1\"] = u_d_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = udb_df, i_bd_or_db_df = db_df, condition_col = \"dptno\", ratio_col = \"cbp_b_in_c_count_ratio\", agg_type=1)\n",
    "u_d_profile_df2[\"udp_similarity_mean_2\"] = u_d_profile_df2.apply(generate, axis=1, i_ubd_or_udb_df = udb_df, i_bd_or_db_df = db_df, condition_col = \"dptno\", ratio_col = \"cbp_b_in_c_user_ratio\", agg_type=1)\n",
    "u_d_profile_df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ub/ud\n",
    "u_b_profile_df2 = u_b_profile_df2[[\"vipno\", \"bndno\", \"ubp_similarity_max_1\", \"ubp_similarity_max_2\", \"ubp_similarity_mean_1\", \"ubp_similarity_mean_2\"]]\n",
    "u_d_profile_df2 = u_d_profile_df2[[\"vipno\", \"dptno\", \"udp_similarity_max_1\", \"udp_similarity_max_2\", \"udp_similarity_mean_1\", \"udp_similarity_mean_2\"]]\n",
    "\n",
    "u_b_profile_df = u_b_profile_df.merge(u_b_profile_df2)\n",
    "u_d_profile_df = u_d_profile_df.merge(u_d_profile_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def formatting(input_df):\n",
    "    where_are_nan = np.isnan(input_df)  \n",
    "    where_are_inf = np.isinf(input_df)  \n",
    "    input_df[where_are_nan] = 0\n",
    "    input_df[where_are_inf] = 0 \n",
    "    return input_df.fillna(0)\n",
    "formatting(user_profile_df).to_csv(\"./csv/\" + directory + \"/user_profile_df.csv\", index=False)\n",
    "formatting(u_p_profile_df).to_csv(\"./csv/\" + directory + \"/u_p_profile_df.csv\", index=False)\n",
    "formatting(u_b_profile_df).to_csv(\"./csv/\" + directory + \"/u_b_profile_df.csv\", index=False)\n",
    "formatting(u_d_profile_df).to_csv(\"./csv/\" + directory + \"/u_d_profile_df.csv\", index=False)\n",
    "formatting(plu_profile_df).to_csv(\"./csv/\" + directory + \"/plu_profile_df.csv\", index=False)\n",
    "formatting(bnd_profile_df).to_csv(\"./csv/\" + directory + \"/bnd_profile_df.csv\", index=False)\n",
    "formatting(dpt_profile_df).to_csv(\"./csv/\" + directory + \"/dpt_profile_df.csv\", index=False)\n",
    "if directory != \"predict\":\n",
    "    label_df.to_csv(\"./csv/\" + directory + \"/label_df.csv\", index=False)\n",
    "print(\"ok\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
